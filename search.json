[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "E155 Blog",
    "section": "",
    "text": "Lab 4 Reflection, and a Foray Into AI\n\n\n\n\n\nA glimpse inside my first week trying to work smarter\n\n\n\n\n\nOct 25, 2024\n\n\nJackson Philion\n\n\n\n\n\n\n\n\n\n\n\n\nMy New Hack for Debugging\n\n\n\n\n\nA new technique that I’m trying to great success\n\n\n\n\n\nOct 18, 2024\n\n\nJackson Philion\n\n\n\n\n\n\n\n\n\n\n\n\nThe Limitations of C and Me\n\n\n\n\n\nWhat the job search is teaching me about coding and myself.\n\n\n\n\n\nOct 10, 2024\n\n\nJackson Philion\n\n\n\n\n\n\n\n\n\n\n\n\nLab 3 Reflection\n\n\n\n\n\nA reflection on Lab 3 and Debugging in general.\n\n\n\n\n\nOct 3, 2024\n\n\nJackson Philion\n\n\n\n\n\n\n\n\n\n\n\n\nLab 2 Reflection\n\n\n\n\n\nA reflection on Lab 2 and why I made a wire octopus.\n\n\n\n\n\nSep 18, 2024\n\n\nJackson Philion\n\n\n\n\n\n\n\n\n\n\n\n\nLab 1 Reflection\n\n\n\n\n\nA brief reflection on Lab 1: Seven Segment Display\n\n\n\n\n\nSep 8, 2024\n\n\nJackson Philion\n\n\n\n\n\n\n\n\n\n\n\n\nMy Learning Goals\n\n\n\n\n\nA discussion of what I want to get out of E155: Microprocessors\n\n\n\n\n\nSep 2, 2024\n\n\nJackson Philion\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "E155 Portfolio",
    "section": "",
    "text": "Hello! My name is Jackson Philion. I’m a senior engineering student at Harvey Mudd College with a focus in Electrical Engineering. I have experience with Digital Design, MCU and FPGA programming in C and SystemVerilog, and love blending these aspects with work in Hardware Engineering.\nThis website contains a record of my work at Mudd in E155: Microprocessor-based Systems. Combining a STM32 MCU on the same board with a iCE40 FPGA, this class challenges students to build their electrical skills while ensuring they have the thorough documentation to back it up. Check out the Labs tab above to see more. Note that this website is under active development as the class proceeds throughout Fall 2024!\nAfter graduating from Concord Academy high school in 2020, I decided to take a gap year to explore my interests in Computer Science and Engineering. I began working with Cobra Puma Golf’s Innovation department to test and prototype new club heads and competitive technology, and finished working with Egghead Ventures on web development and new product prototyping. I returned to Egghead Ventures the following year, as well as taking on a role as a Head Counselor at my high school summer camp. I have since worked with Sol Clarity, a green energy start-up based in Boston, where I designed hardware and produced technical drawings for their upcoming field trial. After studying abroad in New Zealand with the University of Canterbury’s Electrical Engineering department, I look forward to launching a career which aligns with my varied interests. I hope to find the team which lets me design and implement digital circuits while making sure I have the hardware to back it up!\nCheck out the card links below to view my Github and Linkedin."
  },
  {
    "objectID": "posts/lab2-post.html",
    "href": "posts/lab2-post.html",
    "title": "Lab 2 Reflection",
    "section": "",
    "text": "If I recall my reflection from Lab 1 correctly, its main refrain was: “This week was nice, and I learned a lot, but I’m scared for when things get not-so-nice”. Well, this week certainly toed that line, introducing some highs and lows that tested my resolve just a bit.\nAnd to think… the week started so well…\nWhen I first began Lab 2, I was (and this is the best word here) stoked. I was excited for a relatively easy lab that reused a lot of code from last week, taught me a new concept (time multiplexing), and had something cool to show for it. Thats why I got so excited when I saw the specification for Excellence, reading: “Digits on the seven-segment display are upright to the viewer.” At first, I wasn’t sure what to make of this specification. Prof Brake didn’t mean that the digits had to be literally upright – did he? If that was the case, I wondered… well, couldn’t you just tilt the breadboard up to face out towards a room? Surely that can’t be what he means.\nThen I asked a class TA and sure enough, he meant just that. I had to get my digits to stand physically upright."
  },
  {
    "objectID": "posts/lab2-post.html#intro",
    "href": "posts/lab2-post.html#intro",
    "title": "Lab 2 Reflection",
    "section": "",
    "text": "If I recall my reflection from Lab 1 correctly, its main refrain was: “This week was nice, and I learned a lot, but I’m scared for when things get not-so-nice”. Well, this week certainly toed that line, introducing some highs and lows that tested my resolve just a bit.\nAnd to think… the week started so well…\nWhen I first began Lab 2, I was (and this is the best word here) stoked. I was excited for a relatively easy lab that reused a lot of code from last week, taught me a new concept (time multiplexing), and had something cool to show for it. Thats why I got so excited when I saw the specification for Excellence, reading: “Digits on the seven-segment display are upright to the viewer.” At first, I wasn’t sure what to make of this specification. Prof Brake didn’t mean that the digits had to be literally upright – did he? If that was the case, I wondered… well, couldn’t you just tilt the breadboard up to face out towards a room? Surely that can’t be what he means.\nThen I asked a class TA and sure enough, he meant just that. I had to get my digits to stand physically upright."
  },
  {
    "objectID": "posts/lab2-post.html#creating-a-housing-for-uprightness",
    "href": "posts/lab2-post.html#creating-a-housing-for-uprightness",
    "title": "Lab 2 Reflection",
    "section": "Creating a Housing for “Uprightness”",
    "text": "Creating a Housing for “Uprightness”\nThe more I thought about it, the more it represented an interesting challenge. Say you wanted to leave your breadboard flat on the table and read out the digits “upright to the viewer”. One would have to create some sort of contraption to hold the display in place in this upright position. Then, how would one get the electrical contacts to the LED display? A custom wiring harness would do it. As I peeked ahead at Lab 3, I saw that we will use the same hardware again… Wouldn’t that be something cool to bring forward? A standalone LED display with a custom wiring harness that connected up to my development board?\nWith this idea in mind, and the hope that I had time to spare this week, I got straight to work on my hardware schematic and standalone display setup. I figured that I would need to design the hardware from the ground up in order to accommodate this detachable display. I cracked open my favorite CAD software (Onshape), grabbed a pair of calipers, and modelled up this little guy below.\n\nAfter brushing up on my college’s 3D printing quizzes to gain access, I discovered that their suite of brand new machines would serve me incredibly well. Using an extra fine layer height (this is for presentation after all) I printed this result below. \nAfter checking the fit, I found it was perfect!\n\nI planned to loop back around later to make a stand for the housed display. That’s why the display housing has tabs to the right and left – a sturdier display with a hollow core could have rested flat on the desk and routed the wiring down through the display housing and out the back of the stand. I figured that I had a couple more steps to go before I got there though! While I was developing my code and block diagram in parallel, I started work on a wiring harness."
  },
  {
    "objectID": "posts/lab2-post.html#wiring-harness-1",
    "href": "posts/lab2-post.html#wiring-harness-1",
    "title": "Lab 2 Reflection",
    "section": "Wiring Harness #1",
    "text": "Wiring Harness #1\nIt saddens me so greatly that I don’t have an image of this first harness. Sneak Peak: It didn’t work, and it failed epicly. Think, like, slow motion montage of everything falling apart. This was that.\nFirst, I reasoned through some design decisions. I figured that I would want to solder the wires to the display, so that they didn’t easily come off. However, I didn’t want to solder directly to the display pins. That would have left me in an odd spot if I wanted to change anything, or even if I just needed to adjust how the display sat in the housing. So, I snapped off two pieces of 1x9 female PCB headers. I figured that I could plug my display into these two rows, then solder my wires to the through hole pins. Next, I figured I would want to use stranded wire, to avoid fatigue breaks along the wire/solder. After all, I planned to use this guy for the next couple labs – that’s a lot of movement. But, I worried that the stranded wire could easily cause accidental connects once it was shoved up inside the display housing. The through hole pins on the header aren’t that strong either, and could bend together to touch. So, I figured that I would need to add some heat shrink tubing around each connect to make sure it wouldn’t need to be debugged in the future.\nIt is worth noting at this point – I worked for a whole summer where half my job was wire harnesses. I won’t say I love them, because that sounds stupid. But I certainly like them. There is an elegance to an effective harness, and I rarely got to manufacture them myself. So if it sounds like I was going in too deep… I was.\nI wonder if anyone reading this will be able to predict my problem… I certainly wasn’t. First off, the stockroom was out of standard heat shrink tubing in small AWG sizes. They only had these wire-to-wire soldering tubes which fused and protected two separate wires. By cutting these in half and removing the solder in the middle, I was able to get a relatively standard piece of heat shrink tubing. I then got to soldering. I forgot how tricky this could be with stranded wire and only two hands! After an hour or so of soldering a whole PCB header’s worth, I slid my heat shrink down each wire and nestled it in at the base. I headed over to the heat gun that I had found in the analog lab, and turned on low heat.\nInstant problems. The heat shrink tubing I had rigged up apparently had the world’s highest shrinking point. I had to turn the gun up to high and hold it for several seconds to see any change. Do you know what, as it turns out, has a lower melting point? Solder. My solder. The solder I had spend an hour doing. So the whole thing fell apart in front of me.\nThe plastic header was melting. The solder ran in rivers down each pin and pooling in the header. All pins were now one solid contact. The wires fell away as their solder melted. Their jackets dripped down around their frayed and solder-blackened edges. My heat shrink tubes were finally beginning to seal down – around nothing. With the wires gone, they instead sealed off the PCB pins from ever being used again.\nI basically made a really hot, very melted piece of multimedia art that was no longer capable of any useful function. And I am so sad that I did not get a picture of it."
  },
  {
    "objectID": "posts/lab2-post.html#wiring-harness-2",
    "href": "posts/lab2-post.html#wiring-harness-2",
    "title": "Lab 2 Reflection",
    "section": "Wiring Harness #2",
    "text": "Wiring Harness #2\nMy next idea was to use screw terminals as the “header”, or as the connection between display and wire. I figured that I could solder pins to pins and feel relatively confident that they would not make accidental electrical contacts. I could avoid soldering stranded wire entirely, expect maybe to make a solid end to plug into my breadboard.\nThis idea was brilliant. It worked flawlessly. After tragedy, I cannot express how welcome success was. Check out the octopus of wires that now stuck out from my display housing – all perfectly secure and yet removable!\n\nHowever, check out what happened when I tried to plug it in.\n\nI named that image “Rats Nest”. Can you see why?"
  },
  {
    "objectID": "posts/lab2-post.html#migration-to-a-bigger-board",
    "href": "posts/lab2-post.html#migration-to-a-bigger-board",
    "title": "Lab 2 Reflection",
    "section": "Migration to a Bigger Board",
    "text": "Migration to a Bigger Board\nAs soon as I went to actually interface this display with my breadboard, I realized that I was going to have a debugging problem. At this point, I had developed my code enough that I was ready to try running it on an actual display for the first time. I knew that I had thrown my hardware together hastily, anxious to try it out. I had used the only breadboard I had, which was now flying near max capacity. I was confident that if my solution didn’t work the first time, I would have to strip everything down and rewire it on a bigger breadboard. With this scary thought in mind, I plugged it in… and got nothing. Expletive. Pick your favorite.\nJust to drive the point home, this is what I was looking at as I tried to debug my completely non-functional system. I couldn’t get any oscilloscope or multimeter probes anywhere near where I needed them, and following individual wires was like trying to follow an individual spaghetti noodle as you held a wet clump in your hand. But, I have to say, nobody else had a display that floated (as far as I know).\n\nAfter a tedious rewiring, I came to the final hardware solution presented in my Lab 2 report.\nWhat did I learn from this? Ironically, it wasn’t really a lesson learned as much as it was a lesson reminded. I traditionally make overly-neat, meticulously crafted breadboards. I cut each wire to perfect lie-flat length, bend each to fit around and over components, and use my favorite pair of needlenose pliers. What happened this time? Well, partly, I had components which literally floated. I also, however, missed the crucial step of laying out my components beforehand. I didn’t have a good understanding of how many rows I needed, to wire up components like my switches and display resistors. I put myself in a bad situation which I can avoid in the future by completing my design schematic before trying to build out half of it. Additionally, this was a reminder to leave a little wiggle room. My permanent move to a larger board should serve me well in this aspect, but it is worth repeating. I often treat my hardware like I plan to set-it and forget-it. As labs get more complex, this is less realistic."
  },
  {
    "objectID": "posts/lab2-post.html#tragedy-twas-all-for-naught",
    "href": "posts/lab2-post.html#tragedy-twas-all-for-naught",
    "title": "Lab 2 Reflection",
    "section": "Tragedy – ’Twas all for naught",
    "text": "Tragedy – ’Twas all for naught\nAt this point, I had resigned to prototyping on a flat display before trying out my new harness and standalone unit on a working final prototype. Working in lab one day, I heard my friend Alisha laughing at my octopus display. Alisha is one who is likely to strive for excellence marks, so I challenged her: “How did you meet that spec then?”\nShe looked at me with blank eyes and said: “Jackson, what spec? It does not need to be upright.”\nAfter I confirmed with the professor that I had misread the spec, an incredulous me turned into an incredibly disappointed me. At this point, I had invested far more time into the lab than planned, and was no longer on track to finish it by my hopeful Thursday afternoon checkoff. I was willing to pursue the idea when it was an excellence spec, or when it wouldn’t cost me work on next week’s lab – neither condition was true any longer. So, I sadly paused work on my floating octopus and resigned to have my display lie flat like all the others. I resigned to just making sure that the display was “oriented upright to the viewer,” so that digits present themselves in a normal reading manner. Finishing the lab after that was short work – the trickiest part was writing the testbenches. But I lost a lot of flare for it after that. It just wasn’t as exciting any more."
  },
  {
    "objectID": "posts/lab2-post.html#conclusion-and-reflection",
    "href": "posts/lab2-post.html#conclusion-and-reflection",
    "title": "Lab 2 Reflection",
    "section": "Conclusion and Reflection",
    "text": "Conclusion and Reflection\nI think the moral of the story here is that I got overexcited then burnt out too quickly. I still completed a successful lab, albeit way out of the time I had allotted. I still have a great write-up to show for it, and some cool parts that could one day stand alone. I learned a valuable lesson about clarifying specifications at the source, and paying closer attention to when I’m doing something that I don’t see anyone else doing. While that can sometimes be good, it is likely more often a sign that I had missed or misunderstood something. I am, after all, surrounded by some of the best and brightest at Mudd – I am far from the only overzealous one, and certainly not the only one striving to meet all excellence specs.\nIn a more technical sense, I want to get better at writing my testbenches. I did alright this time around, but my display Multiplexer test bench only hit my personal bare minimum. The key thing holding me back here is understanding how to replace the HSOSC module with a testbench generated signal, and understanding how this plays into my test vector readout. I hesitated this time around because I didn’t want to spend forever debugging the testbench alone, rather than the real system. Increasing my proficiency on this front would be a great boon to my EE skills going forward, both in this course and as a practicing professional."
  },
  {
    "objectID": "posts/first-post.html",
    "href": "posts/first-post.html",
    "title": "My Learning Goals",
    "section": "",
    "text": "I remember being a freshman at Harvey Mudd College, living in the room directly across from where I live now as a Senior. I was an aspiring engineer, unsure of what exactly he wanted to actually… engineer. I loved solving problems, but I hadn’t yet figured out how I wanted to apply myself. I remembered talking to the engineering seniors in the singles across the hall – some worked on audio amplifiers and processors while others worked on drone tracking or materials research. I listened intently as people talked about their work. I asked a lot of questions, not about the technical details but about the day-to-day work. Around this time as a freshman, I identified my interest in Electrical Engineering. I loved my introductory Computer Science course, but I didn’t find it to feel as impactful or tactile as I had hoped. I loved physics, but similarly disliked the lack of immediate applications that I could dream for it. Electrical Engineering seemed to strike a perfect balance. Talking with the seniors, I heard about how they spent time working on their code, working on their hardware, and working in the field to apply their creation – it sounded like the perfect fit. I recalled my internship at Egghead with Tom Morris, where he tasked me with finalizing a plan for a cellular-enabled smart outlet. I remembered the excitement of rigging a power cable through my custom housing, connecting to the 3G network, and seeing the SMD LED first flash solid green. In this newly identified interest, I kept an ear out for courses that the successful electrical engineers at Mudd had all taken. E155: Microprocessors stood out as a clear winner."
  },
  {
    "objectID": "posts/first-post.html#intro-engineer-of",
    "href": "posts/first-post.html#intro-engineer-of",
    "title": "My Learning Goals",
    "section": "",
    "text": "I remember being a freshman at Harvey Mudd College, living in the room directly across from where I live now as a Senior. I was an aspiring engineer, unsure of what exactly he wanted to actually… engineer. I loved solving problems, but I hadn’t yet figured out how I wanted to apply myself. I remembered talking to the engineering seniors in the singles across the hall – some worked on audio amplifiers and processors while others worked on drone tracking or materials research. I listened intently as people talked about their work. I asked a lot of questions, not about the technical details but about the day-to-day work. Around this time as a freshman, I identified my interest in Electrical Engineering. I loved my introductory Computer Science course, but I didn’t find it to feel as impactful or tactile as I had hoped. I loved physics, but similarly disliked the lack of immediate applications that I could dream for it. Electrical Engineering seemed to strike a perfect balance. Talking with the seniors, I heard about how they spent time working on their code, working on their hardware, and working in the field to apply their creation – it sounded like the perfect fit. I recalled my internship at Egghead with Tom Morris, where he tasked me with finalizing a plan for a cellular-enabled smart outlet. I remembered the excitement of rigging a power cable through my custom housing, connecting to the 3G network, and seeing the SMD LED first flash solid green. In this newly identified interest, I kept an ear out for courses that the successful electrical engineers at Mudd had all taken. E155: Microprocessors stood out as a clear winner."
  },
  {
    "objectID": "posts/first-post.html#what-i-want-to-walk-away-with",
    "href": "posts/first-post.html#what-i-want-to-walk-away-with",
    "title": "My Learning Goals",
    "section": "What I Want to Walk Away With",
    "text": "What I Want to Walk Away With\nAs I approach this course, I recognize it as a capstone of sorts. While I will pursue other electrical courses while at Mudd, perhaps none will provide a greater boost to my electrical expertise. Further, I plan to directly apply these skills as I pursue my sponsored work with HRL Labs for FPGA in quantum computing control systems. So, I want this class to ultimately help me develop into an electrical engineer who is ready to start a career development program in a professional setting. With that said, I hope to:\n1. Gain an understanding of FPGAs and their applications.\nAs I hope to develop confidence in my career as an electrical engineer, and understanding of FPGAs seems critical. They are a basic building block of everything from simple embedded systems to high-speed computing at the cutting edge of finance. I want to be capable of sustaining technical conversations with employers and coworkers where I can understand how to apply FPGAs. This means understanding how to break a task into a block diagram, understanding the software and Verilog necessary to implement the task, and most importantly – recognizing the gaps in my knowledge that I need to fill in order to manifest my solution.\n2. Increase my Autonomy (by failing more often).\nAn important part of being a team member is understanding when to seek collaboration and when to strike forward for the sake of progress. Increased collaboration may lead to more “correct” results more often, but a dependency on collaboration hinders both your own growth and the efficient progress of the project. Conversely, one might imagine that you can steep-track project progress by focusing on indivual progress. However, this may cause one to lose sight of the project’s overall goals and render contributions meaningless. I find that I more often tend to strive for a perfect solution, meaning that I end up checking in often with coworkers to make sure that I am on “the right track”. I think I would benefit from increasing my autonomy. In order to do this, I have to be willing to try things and fail more often in smaller pieces. I have to be willing to go out on a (safe) limb and experiment, then bring my results to the group. I believe that this will lead to personal growth, making me a better player on my future team."
  },
  {
    "objectID": "posts/first-post.html#final-thoughts",
    "href": "posts/first-post.html#final-thoughts",
    "title": "My Learning Goals",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nWhile I reserve the right to learn more, these are the essential points that I would be disappointed to leave this class without. These are the points that I think will help me kickstart my career in electrical engineering. I thank Harvey Mudd for putting forth the challenge of this class to its students – I have been excited to take it head on since I was a freshman. I believe that challenges like these are what will push me from student to practicioner, and I can’t wait to see the transition take shape. Lab One is already proving to be deceptively simple though not at all easy. So, here we go – Off to the races!"
  },
  {
    "objectID": "posts/post-24-10-25.html",
    "href": "posts/post-24-10-25.html",
    "title": "Lab 4 Reflection, and a Foray Into AI",
    "section": "",
    "text": "Lab 4 was quite different from the prior labs in many ways. For starters, it represented a kind of new beginning. Labs 1 through 3 had all focused on using the FPGA, and had built on each other in a clear way. Lab 1 created the display system, Lab 2 doubled it, and Lab 3 refined the user input experience. Code was recycled, features were added, and the process felt iterative and like a deepening of learning in one particular area. In contrast, Lab 4 was all about learning new microcontroller memory structures, syntax, and modes of thinking."
  },
  {
    "objectID": "posts/post-24-10-25.html#my-ai-background",
    "href": "posts/post-24-10-25.html#my-ai-background",
    "title": "Lab 4 Reflection, and a Foray Into AI",
    "section": "My AI Background",
    "text": "My AI Background\nNow, before I go into more detail, it is worth mentioning what kind of background I have with AI – or, more accurately, I should say with ChatGPT. The answer is slim to none. I didn’t use it at all my Junior year in college, and only used it my sophomore year for some help writing effective thesis statements and summary conclusions. I found that I just didn’t trust it for much else, and even when I did, ended up spending about as much time trying to come up with a good prompt and refining my search. It felt like I got more learning for the same amount of time input, so I just kind of ignored the service.\nFlash forward to this week and ChatGPT has made somewhat of a resurgence in my world. It started when I was working next to Ket on Lab 4, and after creating my timer structures, I asked if I could see what his looked like to see if my syntax and ordering made sense. He said that he hadn’t gotten to that portion yet, and so I continued on for another about 5 minutes until he said he was ready to check. After he showed me his structure, I was shocked to see that it was as thoroughly commented as mine was, and matched nearly exactly. It took me 15+ minutes to check, double check, and add in thorough commenting – how had he made nearly the same product in 5? Turns out, he had written the structure by hand, written a comment format that he wanted, then asked ChatGPT to populate the rest of the comment fields with the appropriate offset and name of the register.\nTwo things surprised to me about this. Firstly, that it nearly exactly matched the human-generated version that I had written. I think it speaks to how far models have come, even under the hood in the past two years. Secondly, I was surprised that I felt a drive in me to engage more with AI for these kinds of tasks. I have found myself to be otherwise very wary of ChatGPT, and I wasn’t expecting this new excitement to rise up. But as I sit here now, I’m thinking about applying it in areas where I’ve already done the hard part – I just need help expanding, commenting, or defining."
  },
  {
    "objectID": "posts/post-24-10-25.html#chatgpt-in-lab-4",
    "href": "posts/post-24-10-25.html#chatgpt-in-lab-4",
    "title": "Lab 4 Reflection, and a Foray Into AI",
    "section": "ChatGPT in Lab 4",
    "text": "ChatGPT in Lab 4\nThis manifested itself in one main way in Lab 4. After I had completed my music playing system, I wanted to implement a song of my own choosing. Intentionally wanting to experiment with ChatGPT as I wrote this optional addendum to my work, I first used ChatGPT to generate a list of ideas of songs that were clearly recognizable and simple to generate with a pure tone buzzer. After it gave me a standard list of Happy Birthday, Twinkle Twinkle Little Star, and Jingle Bells, I prompted it to come up with some more fun and interesting ideas for a young and nerdy college audience. This one was much more fun: Seven Nation Army, Super Mario Bros, Sweet Caroline, Blinding Lights… and the Imperial March from Star Wars! Inspired, I quickly chose a piece of sheet music and set about transcribing it into a C array of Frequencies and Durations.\nI ran into a barrier rather quickly, however – in fact, immediately. I don’t know how to read sheet music. This generated my next idea: Can ChatGPT take in images, and given the proper instructions, translate this into a playable C array? The answer: yes and no, but mostly no. Although it did generate a C array in my requested format, when I tried to play it, only the first three notes sounded right. After investigation and some learning on basic music theory, I realized that while most of the frequencies were correct, ChatGPT had made all of the timings the same, at a quarter note. News flash – the Imperial March does not have only quarter notes. So, I went about transcribing and correcting the output by hand, testing as I went.\nIt took me another about 30 minutes to give up on this idea. No matter what I tried, or how I tried to break up the timing and add rests, it wasn’t playing correctly. It was around this point that I realized that the flaw might have been in the sheet music I found, or at least in my understanding of how to read the sheet music. It showed no visible rests, but some were clearly missing from what the tune should have sounded like. So, I moved to pivot to a new idea.\nAt this impasse, I considered that somebody else had probably done this before. A quick google search pulled up Profe-Electro, an electronics Youtube creator, who had implemented a similar frequency and delay buzzer system on an Arduino. However, his system used the Arduino library of functions and a different format and note structure. This gave me my next idea – could ChatGPT translate this Arduino song into the same format that it had successfully generated for me previously? The answer: yes! After again asking ChatGPT to create me a list of define statements that mapped the sequence of notes to their frequency, I was able to easily implement the system into my C code and run the Imperial March."
  },
  {
    "objectID": "posts/post-24-10-25.html#conclusion",
    "href": "posts/post-24-10-25.html#conclusion",
    "title": "Lab 4 Reflection, and a Foray Into AI",
    "section": "Conclusion",
    "text": "Conclusion\nSo, what came of this exploration? I learned that it was still very much possible to ask too much of ChatGPT. Whether its image recognition isn’t good enough yet, or my request caused it to jump over one too many hurdles, the result was clear – it couldn’t yet perform my whole task for me. However, it was effective at helping me with three parts of the lab. Firstly, it was great for brainstorming songs, and asking it which parts of the songs would be best translated into a buzzer song. Secondly, it was great for answering simple music theory questions that otherwise would have taken me a lot longer on Google. Finally, it was great for the tedious tasks – taking someone else’s existing ideas and translating them into a new format, or generating a list of macros for known frequencies.\nI think I could still do a lot to improve my use of AI – after all, this was my first week since 2022 that I gave it a concerted effort. I have a lot of room to improve my prompts, and I need to tinker more to refine my idea of what ChatGPT is actually good at. I’m not worried that I’ll become overconfident with my use of ChatGPT. I’m far more likely to quit using it because I feel that I cannot trust or rely on it (which we already know you can’t). So, I think it’s going to be a balancing act. I want to try to use it in scenarios where I can easily verify a non-mission critical output, but when the output myself requires repetition and simple translation. I like to imagine a world where I can expand this use in my future coding work, but for now, I just don’t have the confidence in ChatGPT’s work."
  },
  {
    "objectID": "labs/lab4/lab4.html",
    "href": "labs/lab4/lab4.html",
    "title": "Lab 4",
    "section": "",
    "text": "Quick Stats\nTime Spent: 16 Hours, 11 minutes and 51 seconds\nTimers Initialized: 2\nFailed Imperial Marches: 1\nBlown LM386 Amplifiers: 0.5\nHow Helpful the Oscilloscope Was: Very\nDebugger: Thoroughly Stepped\nE85 Lab-goers Annoyed: 4\nE85 Lab-goers Impressed: 0\nE155 Classmates Impressed: 1\nOverall: Success\nSee my Blog Reflection for more!"
  },
  {
    "objectID": "labs/lab4/lab4.html#lab-4-digital-audio",
    "href": "labs/lab4/lab4.html#lab-4-digital-audio",
    "title": "Lab 4",
    "section": "Lab 4: Digital Audio",
    "text": "Lab 4: Digital Audio"
  },
  {
    "objectID": "labs/lab4/lab4.html#lab-task-intro-to-mcu-and-writing-effective-headers",
    "href": "labs/lab4/lab4.html#lab-task-intro-to-mcu-and-writing-effective-headers",
    "title": "Lab 4",
    "section": "Lab Task: Intro to MCU and Writing Effective Headers",
    "text": "Lab Task: Intro to MCU and Writing Effective Headers\nLab 4 tasks students with creating a digital audio system capable of playing a simple tone-based song. Enabled by the MCU for the first time, rather than the FPGA, this lab has an added challenge. Typically, a STM32 programmer would use CMSIS, a standardized framework built for helping users implement MCU functions easily and consistently. Instead, in our lab 4 case, students are tasked with building out their own header files to enable such control. This practice aims to develop the skills needed to parse and implement the 1600 page reference manual, hopefully making future projects easier to understand and implement with or without the aid of tools like CMSIS.\nNote: I need to thank and credit Professor Joshua Brake for providing the Lab 4 starter code here, which lists the C array which encodes the frequencies and delays for Für Elise, and the RCC Configuration tutorial here. The latter tutorial was partially completed during a lecture day, and includes the unmodified .c and .h FLASH files which ensure that code can still be downloaded. It also contains the GPIO files, which I modified to include both port A and port B, and the RCC tutorial itself, which gives a framework for students to enable the PLL."
  },
  {
    "objectID": "labs/lab4/lab4.html#the-hardware",
    "href": "labs/lab4/lab4.html#the-hardware",
    "title": "Lab 4",
    "section": "The Hardware",
    "text": "The Hardware\nThe circuit for this lab was simple – connect an 8 Ohm speaker to the MCU through an audio amplifier stage. We selected the LM386, a common low-power IC often used for audio applications. We were able to hook up this circuit directly as shown by the example application circuit in the data sheet. Our resulting circuit may be seen in Figure 1 below. Note that I ended up removing the final capacitor that ran in series with the speaker, as it seemed to be cutting off the upper end of my frequency spectrum. Everything sounded extra low and down-shifted.\n\n\n\n\n\n\nFigure 1: Schematic"
  },
  {
    "objectID": "labs/lab4/lab4.html#steps-to-enable-sound-output",
    "href": "labs/lab4/lab4.html#steps-to-enable-sound-output",
    "title": "Lab 4",
    "section": "Steps to Enable Sound Output",
    "text": "Steps to Enable Sound Output\nI knew that my ultimate goal was to build a PWM generator capable of producing a desired frequency. Changing this frequency would allow me to produce any tone, or note, I wanted. I also needed a way to precisely control when this PWM triggered and changed frequency. Changing this delay would allow me to control the cadence of the music. Luckily, both of these can be accomplished with the same fundamental unit in an MCU – timers! With this in mind, I created the following task list of big picture action items:\n\nEstablish a known system clock.\nEnable clock output to peripheral timers\nSet a timer for controlled delay\nSet a timer for PWM\nEnable output pin for PWM alternate functionality\n\nNote: For the most thorough description of which Registers to use and Bits to change, see my code, found in my github here.\n\nSteps 1 and 2 – Clock Control\nMy block diagram for this lab presents itself in a less obvious form, but it more clearly outlines the steps that I must go through in order to accomplish the steps above. Starting with Figure 13 (Clock Tree, from page 180 of the reference manual) as a base, I developed the quasi - block diagram in Figure 2 to describe how I would accomplish steps 1 and 2 above. I chose to enable the PLL, using the MSI as a source, as highlighted in Blue. I then set the system clock source to PLL, as shown in Purple. Finally, I could feed these clock signals to the peripheral timers, as shown in Red.\n\n\n\n\n\n\nFigure 2: Clock Source Block Diagram\n\n\n\nNote that I did not leave my choice of where to run the Red timer connections up to chance. I chose timers 2 and 6 to generate my frequency and delay because they had the requisite functionality and could be enabled by the same clock signal. I chose timer 6, one of the most basic timers available on our MCU, as a delay timer. I felt that it would serve as a low-stakes introduction to using timers, helping me build up the skills for enabling the PWM on a separate timer. After all, its only function in my system is to count up a precise delay – a basic function indeed. I chose timer 2 to generate my frequency output because it’s a general purpose timer with a PWM function built in.\nFinally, I want to note the x1 or x2 block along the red line, right before the signal feeds out to the timers. Originally, I did not know how to set this. I have since come to learn that this value is set to x1 automatically if both bus prescalers are equal to 1, and the value is set to x2 in any other case. Since I chose to divide by 2 with both the AHB and APB1 scalers, this block was set to x2. This gave me a final SYS_CLK = 10 MHz, and a TIMER_CLK = 5 MHz.\n\n\nSteps 3 and 4 – Timer Control\nTo describe the steps required to enable Timer 2, I used Figure 325 in the STM32 reference manual as a base. Tracing the required signal path to generate a delay, I produced the quasi - block diagram shown in Figure 3 below. This one was relatively straightforward. The key steps to remember are enabling the control unit after setting the desired prescale and auto-reload values.\n\n\n\n\n\n\nFigure 3: Timer 6 Block Diagram\n\n\n\nTo understand more about how the timer works, I used Figure 328 in the STM32 reference manual, shown in Figure 4 below. I thought about the timer like this: once enabled, the timer counts up. It stores its current count value in the Counter Register. This counting occurs at a rate determined by the counter clock, which is equal to the Internal Clock divided by the Clock Prescaler. The Counter Register continues counting up until it is equal to the Auto Reload Register (not pictured, but can be set by the user).\n\n\n\n\n\n\nFigure 4: Timer 6 Timing Diagram\n\n\n\nWe set the system clock speed such that it is 5 MHz by the time it reaches the timers. We know and can control the prescaler – I set it to 1, essentially meaning that this 5 MHz system clock passes straight through to the counter. So, the counter counts up at a frequency of 5 MHz. In other words, it will count up to 5 million in a full second. That would be useful if I wanted to count seconds, or if the counter register was big enough to store that big a number. However, neither of these are true. So, that’s why we control the Auto Reload Register – it tells the counter when to restart from 0. By carefully choosing the value we put in the Auto Reload Register, we can tell the timer to count up in millisecond increments, microsecond increments, or anything between. For example, if we set it to 1,000, then the counter would count a total of 5 thousand times, instead of 5 million.\nI set my timer so that a single cycle of counting takes 1 millisecond. How does one use this to create a useful delay function? In order to interface the software with the counting hardware, we first need to understand what the software can see. When the timer reaches its maximum, it creates an update event. Listed in the diagram below as (UEV), this is how the hardware signals itself to reset from 0 and continue counting. Once the counting starts again, the hardware automatically resets the UEV bit. So, a user who wanted to use this timer to count up to 10 milliseconds could wait for 10 of these events to generate. However, this requires a strict timing – so, we have a better solution. The UEV bit also sets the UIF bit – Update Interrupt Flag. This flag turns on every time the counter reaches its maximum, and stays on until turned off by software. Turning it on or off does not affect the counting itself. So, by instead tracking this UIF bit, we can make sure that we don’t miss a counting cycle.\nWith this understanding, generating a PWM signal is rather straightforward. Timer 2 has a built in compare function, which outputs 0 if counter is less than the compare number and 1 if the counter is greater than the compare number. If you set the compare number to be half of the Auto Reload Register, then the timer will output a square wave, going from 0 to 1 midway through a single timer cycle. So, you can generate a desired PWM wave by storing select values in the Auto Reload Register (the top value), the Capture/Compare Register (the middle value), and the Prescaler Register (which sets the counter frequency, like TIM6).\n\n\n\n\n\n\nFigure 5: Timer 2 Block Diagram\n\n\n\nHowever, although the idea behind generating a PWM is rather simple, timer 2 is far more complex and requires special attention in its block diagram. Specifically, there are 4 channels, and additional stages of control (ex. output control, capture/compare control). If any of these values is incorrectly set, say for the wrong channel to to the wrong value, the entire chain breaks down. Figure 5 above shows the block diagram path of the signal, highlighting the values that must be updated. In addition, the reference manual contains a section describing which values need to be set to enable PWM output.\n\n\nStep 5 – Output Pin Control\nGreat! We have a way to control a precise delay, and can generate a PWM wave. Except right now, that wave signal is stuck on an internal timer – we need to get it out to a pin so we can interface it with the world. So, we need to follow another path through to an output pin. Most of these pins have alternate functions, allowing them to be connected to some internal system like our timer 2. To understand this signal path, we may look to the quasi - block diagram in Figure 6 below. For understanding more about the software control and interconnects between systems, the table describing these internal connections may be found in the STM32 data sheet (page 55, Table 15).\n\n\n\n\n\n\nFigure 6: Pin Block Diagram"
  },
  {
    "objectID": "labs/lab4/lab4.html#supporting-calculations",
    "href": "labs/lab4/lab4.html#supporting-calculations",
    "title": "Lab 4",
    "section": "Supporting Calculations",
    "text": "Supporting Calculations\nThis section contains the supporting calculations to show the analytical limits of my system’s delay and frequency generation, as well as the analytical and practical calculations which show the accuracy of my PWM frequency and delay timing."
  },
  {
    "objectID": "labs/lab4/lab4.html#delay-limits-calculations",
    "href": "labs/lab4/lab4.html#delay-limits-calculations",
    "title": "Lab 4",
    "section": "Delay Limits Calculations",
    "text": "Delay Limits Calculations\nI designed my delay system to run on Timer 6, the basic timer, set to generate an Update and set the UIF every millisecond (&lt;1% error from MSI and SYS_CLK). Given the design of this timer, it is not possible for my system to count delays under 1 millisecond. Thus, by design my minimum delay is 1 millisecond, with a minimum increment of 1 counting up.\nOn the other hand, my maximum delay is far higher. This timer can run for as long as the MCU is receiving power, which I will assume to be infinitely long (barring the heat death of the universe… or a power outage). However, the MCU needs to knock down the UIF every time it wants to perform a delay. My delay function can only do this for as long as the for loop can continue counting up. Since the for loop counts until it reaches the variable uint32_t milliseconds, then the maximum value of milliseconds is the maximum amount of times that my for loop can be executed. We know that a 32 bit number of all binary 1s, more easily expressed as 0xFFFF FFFF, is equal to 4,294,967,295 milliseconds. Converting to a more human-friendly number, we may say that our maximum delay is about equal to 49.7 days."
  },
  {
    "objectID": "labs/lab4/lab4.html#frequency-limits-calculations",
    "href": "labs/lab4/lab4.html#frequency-limits-calculations",
    "title": "Lab 4",
    "section": "Frequency Limits Calculations",
    "text": "Frequency Limits Calculations\nThe limits of my delay function are relatively simple – the limits of my frequency function are less so.\nThe minimum frequency corresponds to the longest that the timer could count up to its Auto Reload Register. I load the register according to the following quotient function: ARR = TIMER_CLK/freq. Freq can only be an integer value, and we cannot divide by 0 (at the very least, it is undefined by C, even if it may by defined in SEGGER or CMSIS). So, it follows that we can set ARR highest by setting freq to 1. However, as I originally created the function, I did not realize that the 1x or 2x block was automatically set to 2x in my system. I was expecting a TIMER_CLK of 2.5 MHz, not 5 MHz. I noticed this error in testing, and although I initially couldn’t pinpoint the reason, I could fix it using my C function. To account for this 2x error, I passed the desired frequency into the function using a variable givenFreq. The passed variable relates to my actual freq variable as follows: freq = givenFreq/2. In effect, this doubles ARR, fixing the system. However, this fix means that the lowest frequency that I can actually pass into the function is givenFreq = 2, since this must be divided down to freq = 1. This quotient division on givenFreq thus sets my limiting factor. So, for my PWM frequency function, the minimum frequency that I can support is 2 Hz.\nThe maximum frequency corresponds to the shortest that I could set the ARR. In this case, that would be at a value of 1, where givenFreq = 10,000,000, setting freq = 5,000,000, finally making ARR = 1. If the ARR is set to its natural extreme of 0, the counter stops counting. That is to say, we cannot set ARR lower than 1 and still have an output PWM, so this defines our highest frequency. with TIMER_CLK = 5 MHz, ARR = 1 essentially means that the PWM flips each clock cycle. So, the maximum frequency that I can support is 2.5 MHz."
  },
  {
    "objectID": "labs/lab4/lab4.html#pwm-frequency-accuracy",
    "href": "labs/lab4/lab4.html#pwm-frequency-accuracy",
    "title": "Lab 4",
    "section": "PWM Frequency Accuracy",
    "text": "PWM Frequency Accuracy\nThere are two types of supporting calculations that I can provide to back up the accuracy of my frequency PWM generation. Firstly, analytically, we know that TIM2 runs off an internal frequency of 5 MHz. There is some error introduced when I set the Auto Reload Register, since I make use of the quotient function in C, not a true divisor which would account for the remainder. The worst possible remainder on the range of [220-1000]Hz would be a leftover 999. This would equate to a percent error of 999 / 5 MHz, or less than 0.025% introduced error. So, analytically, I expect my PWM wave to be within the given spec of &lt;1% error. Additionally, the MSI internal clock which I use to generate my SYS_CLK is posted as having an error of &lt;1%. So, again, I expect my PWM wave to fall within spec.\nHowever, theory is not practice! Yet, I proved that my frequency is accurate there too, using an oscilloscope. For the set frequencies of 330Hz and 500 Hz, I generated the two oscilloscope plots below.\n\n\n\n\n\n\nFigure 7: 330 Hz Oscilloscope Plot\n\n\n\n\n\n\n\n\n\nFigure 8: 500 Hz Oscilloscope Plot\n\n\n\nBy using the total elapsed time between x number of cycles, I was able to deduce the period of each wave. For the 330 and 500 Hz waves, each had a period of 3.05 and 2.01 milliseconds respectively. This corresponds to a frequency of 327.5 Hz and 497.5 Hz, indicating that my PWM is running the slightest bit slow. However, given respective errors of 0.75% and 0.5%, both tests demonstrate that my error in frequency generation is &lt;1%."
  },
  {
    "objectID": "labs/lab4/lab4.html#delay-accuracy",
    "href": "labs/lab4/lab4.html#delay-accuracy",
    "title": "Lab 4",
    "section": "Delay Accuracy",
    "text": "Delay Accuracy\nI can also support my timer delay, albeit with a caveat. The delay timer that I build was constructed to have a delay of 1 milliseconds. In reality, however, it had a delay of closer to 0.6 milliseconds. I was unable to deduce why this is the case. In Figure 2, there is a 1x or 2x multiplier which I was unable to find the register to control. I wonder if this multiplier was set to 2x, meaning that my analytical timer would count 0.5 milliseconds instead of 1. If there was then some significant unaccounted for lag, either in the system startup, turn off, or with some counter reset, then this could easily turn 0.5 into 0.6 milliseconds. However, this delay was consistent. It was easier to instead scale my Auto Reload Register by the appropriate amount than it was to hunt for the source of this error. After changing it by approximately 1 / 0.6 = 67%, I was able to show with my oscilloscope that each 125 millisecond note played for 126 milliseconds – within a &lt;1% error spec, and within the error range of my MSI clock itself.\n\n\n\n\n\n\nFigure 9: Proof of Accurate Delay (2x125ms notes)"
  },
  {
    "objectID": "labs/lab4/lab4.html#conclusion",
    "href": "labs/lab4/lab4.html#conclusion",
    "title": "Lab 4",
    "section": "Conclusion",
    "text": "Conclusion\nAnd that’s that! I created a working system which, as the System Demo shows at the top, is capable of playing Für Elise and the Imperial March. Check out my Github code here for a more in depth view of the MCU code itself – I put my best effort into thoroughly commenting each function and header definition."
  },
  {
    "objectID": "labs/lab2/lab2.html",
    "href": "labs/lab2/lab2.html",
    "title": "Lab 2: Multiplexed 7-Segment Display",
    "section": "",
    "text": "Quick Stats\nTime Spent: 21 Hours, 35 Minutes, 14 Seconds\nMisunderstood Ideas: 1\nResulting Unnecessary 3D Prints: 1\nResulting Unnecessary Wiring Harnesses: 2\nTestbench: Automatic\nDual Display: Steady, Discrete, and Illuminated\nOverall: Success\nSee my Blog Reflection for more! Dare I say, it contains a particular treat this week."
  },
  {
    "objectID": "labs/lab2/lab2.html#lab-task-double-the-display",
    "href": "labs/lab2/lab2.html#lab-task-double-the-display",
    "title": "Lab 2: Multiplexed 7-Segment Display",
    "section": "Lab Task: Double the Display",
    "text": "Lab Task: Double the Display\nFor the unfamiliar, Lab 1 asked students to read in a set of 4 switches, representing a hex number from h0 - hF. Lab 1 already set up the system to display this number using a single seven-segment display and a set of onboard LEDs.\nLab 2 asks students to build on this system by adding a second set of switches which control a second seven-segment display, and to use LEDs to instead display the sum of the two 4-bit switch inputs as a 5-bit number. Here’s the catch – the lab challenges students to accomplish this doubling in display capacity without instantiating a second module in SystemVerilog, and without using a second set of FPGA pins. In other words, students were tasked with doubling the display outputs without doubling the hardware."
  },
  {
    "objectID": "labs/lab2/lab2.html#enter-time-multiplexing",
    "href": "labs/lab2/lab2.html#enter-time-multiplexing",
    "title": "Lab 2: Multiplexed 7-Segment Display",
    "section": "Enter: Time Multiplexing",
    "text": "Enter: Time Multiplexing\nWe can use time multiplexing to accomplish our double display task. Time multiplexing gives designers a way to utilize common hardware for different inputs and outputs. For example, in a high speed processor, having a unique data line going between every part inside would waste space and be expensive. Instead, designers create a shared pathway, letting different units use it to communicate at different times. I think of it like a landline in a time before cell phones – not every member of the family needs their own. You can install one for the whole house, then schedule a time for each family member to make their calls. Voila, you have time multiplexed your house! Take a look at Figure 2 below. Here, you see a block diagram illustrating the idea, as well as a timing diagram describing how one might lay out the signals in time.\n\n\n\n\n\n\nFigure 2: Time multiplexing block diagram and signal timeline\n\n\n\nIn this case, we have two sets of input switches which want to use the same limited FPGA pins to illuminate their displays. Luckily for us, the human eye isn’t too great at detecting flicker. The United States National Institute of Medicine reports that humans cannot distinguish between flashes of light if the time separating them is less than 10 milliseconds, or over 100 Hz – they will just see a solid glow. On the other hand, our FPGA has an internal oscillator capable of running at 48 MHz, nearly a half million times faster than our eye can detect. So, if we simply use the same set of pins to control either display, turning one on and then the other in sequence, we can easily create the illusion of two simultaneously powered displays while using the same hardware to control them. In my case, I chose a frequency of 500 Hz to be extra safe."
  },
  {
    "objectID": "labs/lab2/lab2.html#hardware-understanding-and-setup",
    "href": "labs/lab2/lab2.html#hardware-understanding-and-setup",
    "title": "Lab 2: Multiplexed 7-Segment Display",
    "section": "Hardware – Understanding and Setup",
    "text": "Hardware – Understanding and Setup\nThe hardware for this lab required a few special considerations. First off, we used a different seven segment display. It still had a common anode schematic, but I instead used a dual display with the following pin mappings as seen in Figure 3 below:\n\n\n\n\n\n\nFigure 3: Dual seven segment display pin mappings\n\n\n\nI was able to use the same calculations from Lab 1 to show that a load resistor of 240 Ohms is sufficient to limit the current to under 10 mA for each segment – recall the maximum is 30 mA. Now, note in the figure above that there is a common anode for each side of the display. That is to say, two connections to power should be made in order to illuminate each half. This is where I may apply a time multiplexing scheme. I can control which display gets powered at any time, making sure that I ground the other anode, in order to effectively switch between the two displays. By doing this at my chosen 500 Hz frequency, the human eye will interpret both displays as solidly on. Then I can run the same seg[6:0] signal to the display pins on both sides. By switching the digit I send down these shared segment pins, and lining these changes up with the L and R power signal, I can effectively control two displays at once with the same 7 lines of segment hardware (plus two power control signals).\nHowever, I now need to configure the common anodes to be controlled low or high via my FPGA pins. One might ask – couldn’t you just use the FPGA pin directly to control the voltage level? The answer is no – the segment draws an unsafe amount of current, too high to be routed directly though the FPGA pins. Specifically, this datasheet about our iCE40 FPGA chip indicates that at 3.3V logic, the maximum I/O current is 8mA. Given that I draw just under this with a single segment, I cannot use it to control the common anodes. Instead, I may use a PNP transistor switch. The simple circuit and calculations which describe its behavior may be found below in Figure 4. In summary, a base resistor of 470 Ohms allows our FPGA pin to control a single point, Vin, to enable to disable each pin. In this process, the maximum current allowed in the transistor pin is limited to 5.5mA, an acceptable maximum. Also note that my diodes should be pulling between 5 and 8 mA, similarly under the FPGA pin current limit, per my Lab 1 calculations.\n\n\n\n\n\n\nFigure 4: Transistor circuit and current calculations\n\n\n\nHowever confident I was with this design, I wasn’t sure how it would interact with a varying load. Recall that each number displayed illuminates a unique sequence of LED segments. Displaying a 1 requires illuminating 2 segments, while displaying an 8 requires illuminating all 7. I wasn’t sure how this varying load would affect the current though the FPGA pin and LED segments, even if I was relatively confident that I had designed my system to operate at the maximums. So, I turned to Flastad, an online circuit simulation tool, to help me understand how my circuit would respond to different illumination regimes. The following Figure 5, Figure 6, and Figure 7 show the three different operational minimums and maximums of the circuit – illumination off, illumination on with a minimum display load, and illumination on with a maximum display load. In each case, we see that the current through each LED segment into the FPGA pins, as well as the base current, is well within specificaiton.\n\n\n\n\n\n\nFigure 5: Falstad Simulation: PNP switch off\n\n\n\n\n\n\n\n\n\nFigure 6: Falstad Simulation: PNP switch on, minimum LED load\n\n\n\n\n\n\n\n\n\nFigure 7: Falstad Simulation: PNP switch on, maximum LED load\n\n\n\nFinally, I considered how I would chose to display the 5 LEDs which represented the sum of both 4-bit switch groups. I decided that I could use the 3 blue LEDs onboard the E155 development board, the same as those used for Lab 1, while also using the two green LEDs above. These could be connected to the FPGA using the fourth and eighth switch on the board’s SW7 8-pole DIP switch.\nWith my connections determined, I created a breadboard circuit according to the following schematic in Figure 8 and proceeded to design my software. Note that the schematic may also be found in PDF form on my Lab 2 github here, under notes and extras.\n\n\n\n\n\n\nFigure 8: Schematic"
  },
  {
    "objectID": "labs/lab2/lab2.html#software-block-diagram-systemverilog",
    "href": "labs/lab2/lab2.html#software-block-diagram-systemverilog",
    "title": "Lab 2: Multiplexed 7-Segment Display",
    "section": "Software – Block Diagram & SystemVerilog",
    "text": "Software – Block Diagram & SystemVerilog\nHaving designed the hardware, I proceeded to plan out my software implementation. I first created a block diagram to describe my system, as found in Figure 9 below. Note that I included a sort of Finite State Machine, or FSM. Well, a quasi-FSM. At the very least, something that is best described by a Moore FSM diagram. In this case, I wanted to switch between two states, displayL and displayR, at a chosen frequency “toggleFreq”. Since I want the display to flash at 500 Hz, I set the toggleFreq to 1000 Hz since the switching nature of the FSM effectively halves the toggleFreq. This diagram, in Figure 10, describes the Toggle FSM block in Figure 9.\n\n\n\n\n\n\nFigure 9: Block diagram\n\n\n\n\n\n\n\n\n\nFigure 10: Rudimentary FSM diagram to explain display switching behavior\n\n\n\nWith this understanding laid out, I proceeded to write my SystemVerilog code. This may be found in the FPGA folder on my Lab 2 github here. Aside from some debugging trying to pass parameters to my frequency generation module, it was relatively smooth sailing."
  },
  {
    "objectID": "labs/lab2/lab2.html#simulation",
    "href": "labs/lab2/lab2.html#simulation",
    "title": "Lab 2: Multiplexed 7-Segment Display",
    "section": "Simulation",
    "text": "Simulation\nFor this lab, I was easily and effectively able to write a testbench to demonstrate that my LED logic. The testbench code may be found on my Lab 2 Github, and the waveform and successful run message may be seen in Figure 11 below.\n\n\n\n\n\n\nFigure 11: LED testbench success – note the message, 0 errors across 8 tests\n\n\n\nRecall that lab 1 already demonstrated (by automated testbench) the successful functioning of the seven segment logic module. Similarly, I have demonstrated that my frequency generator module is effective, and I continue to use/reuse it in this lab with a different frequency parameter.\nThe tricky module to thoroughly test in an automated bench is the displayMultiplexer module. For this, I decided to use a hybrid manual/automatic testbench. I removed the internal oscillator and frequency generator from the module, and instead passed in my own toggleFreq line. I chose to simulate this signal at a rather rapid pace, letting me easily see whether the display was switching or not in simulation. The automatic part of the testbench involved using a .tv file to load in my switch inputs and to generate waveforms of my expected illuminated outputs. The manual part of the testbench involved checking the results. I basically ran the toggle signal out of sync with the testbench’s internal clock, meaning that I wouldn’t be sure what to read out, when. Instead of finagling the two signals to sync up, I decided that manually checking was both easier and more effective. Figure 12 shows my view of the whole simulated testbench, including the 4 test points. For these test points, I chose to display 00, 06, C9, and F3. I figured that if these all displayed the right segments, and the display signal toggled as expected, then I could demonstrate the module was working. Figure 13 shows a close up example of one of my test points, as well as some marked analysis that demonstrated my thinking.\n\n\n\n\n\n\nFigure 12: Full display testbench waveform\n\n\n\n\n\n\n\n\n\nFigure 13: Annotated close up of one test point from the display testbench\n\n\n\nNote that these images may be found also in the extras folder of this lab’s Github here. In any case – all signals generated as expected! Testbench success for all modules!"
  },
  {
    "objectID": "labs/lab2/lab2.html#final-system",
    "href": "labs/lab2/lab2.html#final-system",
    "title": "Lab 2: Multiplexed 7-Segment Display",
    "section": "Final System",
    "text": "Final System\nAfter assembling the final pieces together and running the programmer, the system worked as expected. The display itself was a touch dimmer than I may have liked – I think part of the problem was the color I chose. I could have boosted the current values to get a brighter display, but as Figure 4 showed, I had already thought carefully about my tolerated currents and did not wish to push my luck. Thus, I yield my full system, shown in Figure 14.\n\n\n\n\n\n\nFigure 14: Complete system\n\n\n\nA final reminder that full images, source code, and more can be found in this lab’s Github here. In addition, to learn more about the mysterious “Misunderstood Idea” and “Unnecessary” 3D prints and wire harnesses that I mentioned in the top stats, check out my blog post for this week! So much work gone to… well, not waste, but… to the blog post! Until next week."
  },
  {
    "objectID": "labs/lab7/lab7.html",
    "href": "labs/lab7/lab7.html",
    "title": "Lab 7",
    "section": "",
    "text": "Quick Stats\nTime Spent: 17 Hours\nFSMs: surprisingly, only 2\nDesign Time | Build Time ratio: 50 | 50\nOverall: Simulated Successfully"
  },
  {
    "objectID": "labs/lab7/lab7.html#lab-7-the-advanced-encryption-standard",
    "href": "labs/lab7/lab7.html#lab-7-the-advanced-encryption-standard",
    "title": "Lab 7",
    "section": "Lab 7: The Advanced Encryption Standard",
    "text": "Lab 7: The Advanced Encryption Standard\n\n\n\n\n\n\nFigure 1: Successful Testbench Highlight"
  },
  {
    "objectID": "labs/lab7/lab7.html#lab-task-implement-aes-encryption-on-our-fpga",
    "href": "labs/lab7/lab7.html#lab-task-implement-aes-encryption-on-our-fpga",
    "title": "Lab 7",
    "section": "Lab Task: Implement AES Encryption on our FPGA",
    "text": "Lab Task: Implement AES Encryption on our FPGA\nThis lab challenges students to implement a system which encrypts a 128-bit message according to the Advanced Encryption Standard (AES) as outlined in the 46-page specification here. This lab is unique in that it is more prescribed than others. Rather than accomplish a task by any means we choose, this lab asks students to create an encryption device which mirrors every step of the well-known encryption algorithm. Students still have flexibility to design how we choose, but the final product must meet strict specifications in order to function as intended."
  },
  {
    "objectID": "labs/lab7/lab7.html#getting-to-know-aes",
    "href": "labs/lab7/lab7.html#getting-to-know-aes",
    "title": "Lab 7",
    "section": "Getting to know AES",
    "text": "Getting to know AES\nI created the following flow diagram for myself to understand the system I planned to implement. Figure 2 shows the iterative process that AES performs. Given a 128-bit plaintext message and a 128-bit key message, our version of AES performs 10 rounds. Each step is described in detail within the AES standard, and serves to convolute and confuse the plaintext message in a predictable way until it results in an unintelligible 128-bit cyphertext message. The magic of the system is that a recipient who has the decryption key would be able to perfectly reverse the process and decipher the original plaintext message. However, to any interceptor without the decryption key, the encryption process is nearly impossible to reverse (even though each step is predictable)!\n\n\n\n\n\n\nFigure 2: AES Flow Diagram"
  },
  {
    "objectID": "labs/lab7/lab7.html#implementing-as-hdl",
    "href": "labs/lab7/lab7.html#implementing-as-hdl",
    "title": "Lab 7",
    "section": "Implementing as HDL",
    "text": "Implementing as HDL\nWhen turning the AES process into implementable systemVerilog, I began by sketching a rough block diagram of the final top module. This left me with Figure 3 below.\n\n\n\n\n\n\nFigure 3: Rough top Module Block Diagram\n\n\n\nThe core module is the most complex, housing all of the logic necessary to support the 4 operations of AES. Further, the core module is responsible for coordinating these steps, setting appropriate delays, and asserting the final done output. In order to refine the process, I created Figure 4, a hardware-level design of what the core module might look like. Note that any hanging control signals are to be controlled by the embedded FSM – I created this block to understand how each part was connected, not yet how it was controlled.\n\n\n\n\n\n\nFigure 4: Core Block Diagram\n\n\n\nReading the specification, one realizes that the addroundkey function is relatively complex. The shiftRows and mixColumns functions are both fully executable using a combinational block with only 1 cycle of delay between storing the output. The subBytes function is more complex. It requires embedded RAM blocks to store a look up table for substitution, as well as 2 cycles of delay to account for the time it takes to fetch a value out of the table. Yet, this function was built largely for us within the starter code. This leaves us with the addroundkey function, which requires careful manipulation of individual bytes within the 128-bit originalKey according to the process roughly outlined in Figure 5 below.\n\n\n\n\n\n\nFigure 5: Rough Outline of Key Schedule Process\n\n\n\nThus, I also paid special attention to drawing the full hardware implementation of the addroundkey function out. I included a key_schedule module within to assist the function, and a key_fsm further embedded to control the litany of control signals and timing necessary.\n\n\n\n\n\n\nFigure 6: addroundkey Function Block Diagram"
  },
  {
    "objectID": "labs/lab7/lab7.html#adding-control-signals-fsms",
    "href": "labs/lab7/lab7.html#adding-control-signals-fsms",
    "title": "Lab 7",
    "section": "Adding Control Signals (FSMs)",
    "text": "Adding Control Signals (FSMs)\nIn order to control the control signals within the key_schedule and core modules, I created two separate FSMs. They communicate with each other through the addroundkey Start and Done bits, with the core FSM directing the key FSM on when to begin a processing cycle. See the state diagrams in Figure 7 and Figure 8 below.\n\n\n\n\n\n\nFigure 7: core_fsm Module State Diagram\n\n\n\n\n\n\n\n\n\nFigure 8: key_fsm Module State Diagram"
  },
  {
    "objectID": "labs/lab7/lab7.html#final-code",
    "href": "labs/lab7/lab7.html#final-code",
    "title": "Lab 7",
    "section": "Final Code",
    "text": "Final Code\nSee my github here for the full source code, organized as follows:\n\nThe MCU folder contains all custom libraries and the main.c source file necessary to run a complete SPI system between the MCU and FPGA. This code was given verbatim by Prof Brake in the Lab 7 Starter Code.\nThe FPGA folder contains a source folder, holding all of the source code (including aes.sv). It also includes the Lattice Radiant project, used to synthesize and download the source code, and the ModelSim project, used to simulate and debug the source code. Note that all non- aes.sv files in the source are part of the starter code package, as well as some parts of aes.sv. The core of my generative work may be found by reading this report or exploring aes.sv.\nThe notesAndExtras folder contains any additional notes, images, etc which support the project."
  },
  {
    "objectID": "labs/lab7/lab7.html#simulation-results",
    "href": "labs/lab7/lab7.html#simulation-results",
    "title": "Lab 7",
    "section": "Simulation Results",
    "text": "Simulation Results\nAfter all this design work, my system simulated like a charm! I was quickly able to receive the testbench successful message, and verify by tracking the waveforms that my system responded as expected. Figure 9 and Figure 10 below show the beginning and end of the successful aes_core simulation, respectively. Note the successful run messages in the bottom left.\n\n\n\n\n\n\nFigure 9: aes_core Testbench Success – Beginning\n\n\n\n\n\n\n\n\n\nFigure 10: aes_core Testbench Success – Ending\n\n\n\nFinally, I was able to switch over to the SPI full-system testbench and similarly demonstrate success, as shown in Figure 11 below. Again, note the successful message in the bottom left.\n\n\n\n\n\n\nFigure 11: aes Full System Testbench Success"
  },
  {
    "objectID": "labs/lab7/lab7.html#physical-hardware-results",
    "href": "labs/lab7/lab7.html#physical-hardware-results",
    "title": "Lab 7",
    "section": "Physical Hardware Results",
    "text": "Physical Hardware Results\nAs I moved to implement my system on my FPGA, I did not have to make any structural changes. I had already built my system to minimize the use of non-essential logic blocks. As such, I was able to easily synthesize and fit my logic on my FPGA.\nHowever, I did have some timing errors within some of my longer control signals which stretched throughout the system. Yet, I was able to easily fix these errors by halving my clock frequency, from 48 MHz to 24 MHz. Note that under these conditions, I expect my AES system to take about 5 µs to complete across a total of 135 clock cycles. Wicked fast!\nAs I downloaded and synthesized my system, I was disappointed to see that PA10, the “unsuccessful transmission” LED, lit up upon my first system test. I hooked it up to the logic analyzer to diagnose the problem. I was able to demonstrate that the MCU was correctly sending out ALL signals – including both the plaintext and originalKey messages. Figure 12 below shows the proper beginning 3 bytes of the plaintext message.\nNote on Logic Analyzer Lines For Figure 12 and Figure 13, D0 is CS, D1 is SCLK, D2 is COPI, D3 is CIPO. They are maddeningly mislabelled to the upper left and I could not remove these ghost labels.\n\n\n\n\n\n\n\n\n(a) Successful start to plaintext, h32\n\n\n\n\n\n\n\n(b) Successful next two bits, h43 & hF6\n\n\n\n\n\n\nFigure 12: Successful Plaintext Messages\n\n\n\nNext, I checked to ensure that the transition between plaintext and originalKey was flawless. Figure 13 below shows the proper transition on the logic analyzer, as well as the proper ending to originalKey.\n\n\n\n\n\n\n\n\n(a) Successful plaintext end, originalKey start, h34 & h2B\n\n\n\n\n\n\n\n(b) Successful end two bits of originalKey, h4F & h3C\n\n\n\n\n\n\nFigure 13: Successful originalKey Messages\n\n\n\nAdditionally, I went back and recreated these instances while tracking the Load and Done bits. Both operated as expected. The gap between the two is nearly exactly 5 µs, exactly as predicted by my analysis of the FPGA HDL system. Yet, the problem seems to arise once the FPGA begins to shift the cyphertext back out. Figure 14 below shows the first unsuccessful bit of cyphertext.\nNote on Logic Analyzer Lines For Figure 14, D0 is CS, D1 is SCLK, and D2 is COPI. Then, things change. D7 is CIPO, as the line was more reliable for some reason. I also added Load as D4, seen dropping low just at the start of Figure 14. Finally, I added Done on D5, shown asserting the expected 5 µs after Load drops.\n\n\n\n\n\n\nFigure 14: Unsuccessful Start to cyphertext (expected h39, actual hD9)\n\n\n\nAfter playing around with the timing, the simulation, and my FSMs, I was unable to reproduce or understand this error in any fixable way. It seems to simulate properly, but the hardware is errant somewhere. I double checked my switch positions (to make sure the MCU and FPGA were communicating properly), traced the logic analyzer bit-by-bit for an error (which would propagate throughout the entire cyphertext message), and considered multiple different orderings of resetting or activating the MCU and FPGAs independently. I checked the traces before these logic analyzer packets to check for errant data or Load/Done signals. My next steps would be to test with a partner’s hardware to isolate the problem down to either software or hardware – recall that I theorized I had a short somewhere on my FPGA in Lab 3. Although this is likely not the solution, since the logic analyzer signals acted as expected, I would be remiss not to try it. Then, I would begin slowly breaking out individual signals from within the FPGA and examining them on the logic analyzer. This seems to be the only surefire way to diagnose the issue, as all the software tools at my disposal seemed to indicate that the system should synthesize beautifully."
  },
  {
    "objectID": "labs/lab1/lab1.html",
    "href": "labs/lab1/lab1.html",
    "title": "Lab 1: FPGA and MCU Setup and Testing",
    "section": "",
    "text": "Quick Stats\nTime Spent: 18 Hours\nSystemVerilog Modules Written: 4\nSoftware Installs/Tutorials: 4\nTestbench: Eventual Success\nOverall: Success\nSee my Blog Reflection for more!"
  },
  {
    "objectID": "labs/lab1/lab1.html#prelab-skills",
    "href": "labs/lab1/lab1.html#prelab-skills",
    "title": "Lab 1: FPGA and MCU Setup and Testing",
    "section": "Prelab Skills",
    "text": "Prelab Skills\nLab 1 introduces students to some foundational elements of the class before asking them to do their first piece of generative design work. Chiefly, it introduces students to three key softwares that will be essential to success throughout the rest of the class:\n\nThe FPGA design software Radiant Lattice, which is used for implementing designs onto the FPGA and mapping pin ins and outs. This is new to most students.\nThe MCU design system SEGGER Embedded Studio, which most students have experience with but have not yet connected to an ARM processor.\nGit and Github tools, which is a required organizational tool in this class due to its importance throughout personal and professional work in coding and electrical engineering.\nQuarto website builder, a software system added as an extension to VSCode which has allowed me to build up this portfolio.\n\nFor all intents and purposes, I was a complete beginner with all three of these tools. Thus, the majority of my work in Lab 1 was spent combing through posted class tutorials, checking with online walkthroughs, and building shorthand cheat sheets to help contain the rush of new information. The good news? I now feel comfortable building a raw .sv file from scratch and using Radiant Lattice and Modelsim to integrate and push it to the FPGA. I also feel more confident than I should about building out a test bench – I have yet to integrate an automated one successfully, but I can imagine what I will change for my next iteration in lab 2. It successfully compiled but failed to pull in my testvector.tv file. I realize now that it was in fact a hidden testvector.tv.txt file – Windows has to stop hiding extensions! I also have numerous working testbenches to pull from in my E85 digital electronics work, and thoroughly enjoyed the satisfaction back then of writing a thorough test bench! All that is to say, I am excited to refine my testbench next week and feel confident that I have a route forward. This lab did not involve SEGGER to any significant degree, so I will hold off discussion of that software until a future week.\nI have also built a basic level of fluency with git – I’m happy to report that the cheatsheats barely get any use! Initializing, adding, branching, committing, pushing and pulling are second nature at this point. This was due partially to a hugh warm up period in which I accidentally created 4 different repositories for Lab 1. Combing through this mess to understand what happened and how to fix it contributed significantly to my learning. I still have to look up some commands for finding the correct remote address, and sometimes find myself using the GitHub desktop app for some arranging. However, I mostly use the bash command terminal, and have gotten comfortable interfacing with the lab computers to continue coding projects across any desktop I choose. I still need to build significant fluency with merging and managing branches after creation. I can walk through the steps, but I am left uncomfortable with more than one branch left open at a time and often delete branches immediately after their creation. I think I have yet to fully understand how branches will be a benefit to my work.\nQuarto is also a work in progress. Consider the design of this page my first real world test of this skill – did I succeed? How can I improve? This is what I will ask myself in preparation for my lab 2 page next week."
  },
  {
    "objectID": "labs/lab1/lab1.html#lab-task-seven-segment-display",
    "href": "labs/lab1/lab1.html#lab-task-seven-segment-display",
    "title": "Lab 1: FPGA and MCU Setup and Testing",
    "section": "Lab Task: Seven Segment Display",
    "text": "Lab Task: Seven Segment Display\nAfter the preliminary skills introduction, the primary task of Lab 1 is rather simple.\nThe task:\n\nTake as an input 4 switches, set in order to each represent a consequitve input bit.\nControl a seven segment display to read out the 16 hexidecimal digits from 0 to 15 (or h0 to hF), which correspond to the 4 bit input.\nIn addition, control 3 onboard LEDs to obey the following truth tables with relation to the switch inputs:\n\n\nTable 1: led[0] Truth Table\n\n\nS1\nS0\nled[0]\n\n\n\n\n0\n0\nOFF\n\n\n0\n1\nON\n\n\n1\n0\nON\n\n\n1\n1\nOFF\n\n\n\n\n\n\nTable 2: led[1] Truth Table\n\n\nS3\nS2\nled[1]\n\n\n\n\n0\n0\nOFF\n\n\n0\n1\nOFF\n\n\n1\n0\nOFF\n\n\n1\n1\nON\n\n\n\n\n\n\nTable 3: led[2] Truth Table\n\n\nled[2]\n\n\n\n\nBlink at 2.4 Hz\n\n\n\n\n\nWith the task laid out, and my skills adequately built up, I tackled the lab by first attempting to understand the seven segment display."
  },
  {
    "objectID": "labs/lab1/lab1.html#understanding-the-display-inputs-and-outputs",
    "href": "labs/lab1/lab1.html#understanding-the-display-inputs-and-outputs",
    "title": "Lab 1: FPGA and MCU Setup and Testing",
    "section": "Understanding the Display, Inputs, and Outputs",
    "text": "Understanding the Display, Inputs, and Outputs\nI began my task by trying to understand the seven segment display. This would give me an idea of how many signals I needed to run to it, and how to map out a truth table which would describe each hex number. My selected display unit had a clearly printed serial number on it, which corresponded to the following Jameco Link and the following data sheet. Based on these resources, I derived that I could control the segments of my display via the following pin mapping:\n\n\n\n\n\n\nFigure 2: Seven segment display pin mapping\n\n\n\nNote that this component uses a Common Anode, attached to the manufacturer’s pin 3 and pin 8 of the display. That is to say, by connecting my high voltage rail (in this case 3.3V) to either pin 3 or 8, it would supply the positive anode for every segment. The pins then could be controlled at logic high, leaving the segment off with 0V across it, or logic low, to supply the voltage differential which draws current through the segment and illuminates it. However, the forward voltage of these segment diodes is listed at 2.1V with a maximum forward current of 30 mA [see Jameco Datasheet]. Thus, in order to limit the current, as well as to bridge the remaining 1.2V gap between the positive rail and ground, a resistor needs to be added in series with the segment. In order to reduce the current load on my chip, I chose to operate the segments at a relatively low 5mA of forward current. Using this 1.2V gap and 5mA desired current, I was able to calculate a desired resistor value of 240 Ohms. Figure 3 below elucidates this point by supplying additional calculations and equations.\n\n\n\n\n\n\nFigure 3: Current calculations for seven segment display\n\n\n\nI chose to wire a resistor up to each segment in order to illuminate the segments equally brightly. If I chose to wire two segments up with the same resistor to ground, there would be no issue – the calculations might change, but with an operating current range between 5 and 30 mA, there is plenty of room to drive multiple segments with the same resistor. However, this would cause inequalities in current across the segments of the display, causing inequalities in illumination intensity. To maintain the same visible level of illumination, I thus opted to use a resistor for each segment I chose to illuminate. You can look ahead at the schematic I use down in Figure 6.\nI finally had to decide how I wanted to illuminate the display to represent each digit. I first drew a design of each character as it would appear on the display, as seen in the upper portion of Figure 3 below. Understanding that I would need 7 lines of input to control the desired segments, I was able to determine that I needed an output signal of seg[6:0]. Using the digit design and these seg outputs, I then derived the truth table in the lower portion of Figure 4. This truth table allows me to describe exactly which signals need to be illuminated to represent each digit. Note a blank square is an implied 0, or “seg[i] off.”\n\n\n\n\n\n\nFigure 4: Digit design and truth table\n\n\n\nFinally, there is the matter of the 3 onboard leds which should map to the oscillator and input switches. However, both led0 and led1 may be represented by simple “xor” and “and” operations in the FPGA, respectively. The final led2 output was dictated by an oscillator which similarly might be represented by an operation on the FPGA. None of the led signals required any external hardware that was not already onboard the E155 development board. Thus, I did not consider these outputs until I did my design in SystemVerilog.\nWhich is a perfect segue into the next section! Having understood the functionality of the display, the circuitry I needed to construct around it, and the truth table I wanted to implement, I finally had to consider how I would use the FPGA to generate my seg[6:0] and led[2:0] signal outputs using SystemVerilog language."
  },
  {
    "objectID": "labs/lab1/lab1.html#system-design",
    "href": "labs/lab1/lab1.html#system-design",
    "title": "Lab 1: FPGA and MCU Setup and Testing",
    "section": "System Design",
    "text": "System Design\nI had most fun in this lab with the system design in SystemVerilog. It was always one of my favorite pieces of E85 Digital Electronics, and this held true for this first lab of E155. Figure 5 below describes the abstract view of inputs and outputs that my SystemVerilog modules are based upon.\n\n\n\n\n\n\nFigure 5: SystemVerilog Block Diagram\n\n\n\nUsing this diagram, I began to build out my code in SystemVerilog. You can find my .sv code files at in by Lab 1 github repository here.\nAdditionally, you can find the final schematic in Figure 6 below. Note that I hooked up my breadboard pins first at my convenience, then went back after the fact and used Lattice Radiant to assign the pin outputs. This schematic also shows how I hooked the seven segment display up with the common anode and separate resistor for each segment.\n\n\n\n\n\n\nFigure 6: Schematic and pin mappings"
  },
  {
    "objectID": "labs/lab1/lab1.html#simulation",
    "href": "labs/lab1/lab1.html#simulation",
    "title": "Lab 1: FPGA and MCU Setup and Testing",
    "section": "Simulation",
    "text": "Simulation\nAfter writing my code, I endeavored to simulate its proper function using ModelSim. Note that I would have wanted to use the Questa simulator built into Lattice Radiant, but licensing issues left me using the good old desktop app instead. I first ran a series of forces to set my inputs and verified that each output read as intended. The results of this may be seen in Figure 7 below. Note that the raw image may be viewed, along with the source code, at my Github here.\n\n\n\n\n\n\nFigure 7: Forced simulation demonstrating proper inputs and outputs\n\n\n\nHowever, I wanted to stretch myself to write an automatic testbench instead. I believe that this skill will be instrumental for my SystemVerilog going forward, and I wanted to dust off my testbench-writing-chops right away. After many attempts (and finally removing the .txt extension from my .tv file), I was successful! It does not yet run automatically, needing instead to be fed the command “run 163” after simulation start. Yet, the test bench displays zero errors across each test case (which was all of them). It loads and evaluates each test vector from the .tv file. I am incredibly pleased, and aim to jump off of this first test bench in order to write my next one for lab 2. The successful run results may be seen in Figure 8 below, yet again, the raw image may be found on my github here.\n\n\n\n\n\n\nFigure 8: Testbench simulation demonstrating proper ins and outs, loading of test vectors, and zero errors"
  },
  {
    "objectID": "labs/lab1/lab1.html#completed-system",
    "href": "labs/lab1/lab1.html#completed-system",
    "title": "Lab 1: FPGA and MCU Setup and Testing",
    "section": "Completed System",
    "text": "Completed System\nFinally, with a system designed and tested, I prepared to upload it to my FPGA. I ran into multiple errors on one particular lab computer with programming. While the computer could detect the FPGA and the linking cable, the connection would fail when trying to run the final step. However, after switching to a new computer which a friend had used successfully, I was able to download the code to my system and demonstrate its success! The LED system worked as intended. I did not carefully clock the frequency of led[2], intended to be 2.4Hz. It was certainly doing between 2-3 cycles per second, so I assumed that it was working as intended. However, next time, testing this more thoroughly may reveal further issues for investigation – hard to say without nailing down a measured frequency. However, back to the success! Below you can find Figure 9 with the full system shown, as well as Figure 10 demonstrating that the seven segment display responds as intended with equally bright segments.\n\n\n\n\n\n\nFigure 9: The completed system\n\n\n\n\n\n\n\n\n\nFigure 10: Demonstration of each digit illuminated correctly in final design\n\n\n\nThus concludes my interactions with Lab 1. You can find a reflection of this weeks work in the blog postings, or can head on over to Lab 2 and see what’s next! Spoiler alert: We’re going to try and double the amount of displays without doubling the GPIO burden."
  },
  {
    "objectID": "labs/lab6/lab6.html",
    "href": "labs/lab6/lab6.html",
    "title": "Lab 6",
    "section": "",
    "text": "Due to changes in the course’s arrangement and my personal goals, my individual work on Lab 6 was paused in favor of instead working towards the Final Project. Check out my report on the final project here! My partner and I implemented a Fast Fourier Transform on our MCU which processed an audio signal. We captured the signal using the ADC and DMA after sending it through a custom analog amplifier. Then, we displayed the signal out to the user via an LCD driver built within our FPGA."
  },
  {
    "objectID": "labs/lab6/lab6.html#lab-6-the-internet-of-things-and-serial-peripheral-interface",
    "href": "labs/lab6/lab6.html#lab-6-the-internet-of-things-and-serial-peripheral-interface",
    "title": "Lab 6",
    "section": "",
    "text": "Due to changes in the course’s arrangement and my personal goals, my individual work on Lab 6 was paused in favor of instead working towards the Final Project. Check out my report on the final project here! My partner and I implemented a Fast Fourier Transform on our MCU which processed an audio signal. We captured the signal using the ADC and DMA after sending it through a custom analog amplifier. Then, we displayed the signal out to the user via an LCD driver built within our FPGA."
  },
  {
    "objectID": "labs/lab5/lab5.html",
    "href": "labs/lab5/lab5.html",
    "title": "Lab 5",
    "section": "",
    "text": "Quick Stats\nTime Spent: 14 Hours, I stopped counting minutes and seconds\nTimers Initialized: 2 - 1 = 1\nConsistent Surprise (you’ll see): 22%\nCMSIS: Used Effectively\nTimes I Asked Xavier to Borrow the Tachometer: 1 (he just let me have it)\nIndividual Tachometer Measurements: &gt;100 (thanks Xavier!)\nDC Motors in the Lab: Too Hard to Find\nOverall: Success"
  },
  {
    "objectID": "labs/lab5/lab5.html#lab-5-interrupts",
    "href": "labs/lab5/lab5.html#lab-5-interrupts",
    "title": "Lab 5",
    "section": "Lab 5: Interrupts",
    "text": "Lab 5: Interrupts"
  },
  {
    "objectID": "labs/lab5/lab5.html#lab-task-read-in-a-motors-encoder-for-rpm",
    "href": "labs/lab5/lab5.html#lab-task-read-in-a-motors-encoder-for-rpm",
    "title": "Lab 5",
    "section": "Lab Task: Read in a Motor’s Encoder for RPM",
    "text": "Lab Task: Read in a Motor’s Encoder for RPM\nIn this lab, students were tasked with obtaining the rotational speed of a DC motor using a built-in encoder. After determining this speed, students printed it out to the user in a method of their choosing."
  },
  {
    "objectID": "labs/lab5/lab5.html#understanding-the-hardware",
    "href": "labs/lab5/lab5.html#understanding-the-hardware",
    "title": "Lab 5",
    "section": "Understanding the Hardware",
    "text": "Understanding the Hardware\nI was completely unfamiliar with quadrature encoders before this lab, but have rapidly come to recognize their utility. Professor Joshua Brake created the following animation, in Figure 1, to describe their behavior. It can be found in the prompt for Lab 5 here. I found it to be the most effective tool for gaining an understanding.\nThis diagram shows the waveforms generated by our DC motor’s encoder, which consists of two lines: an A and a B. Using just these offset waveforms, one can determine both the rotational speed and direction of the motor. Finding the speed is easy – it’s directly linked to the frequency of the wave. In Figure 1, a single rotation contains 6 dark and 6 light sectors, generating 6 rising edges and 6 falling edges on the waveforms A and B. By counting the time between edges, whether one counts between two or waits for a full cycle of twelve, one can manipulate this value to determine the revolutions per second of the motor. Alternatively, by counting the amount of edges in a given amount of time, one can similarly determine the motor’s rotational velocity.\n\n\n\n\n\n\nFigure 1: Quadrature Encoder Diagram Animation, from Professor Joshua Brake here\n\n\n\nThe direction, on the other hand, is less straightforward. It may not be immediately obvious how one can track the direction just from these alternating waveforms. The key idea is that the offset between the two waves generates a unique pattern which depends on the direction of spin. This is easiest for me to visualize if I track a single trough on the lower B waveform. You’ll notice that within the bounds of one of these low B troughs, the A wave is low on the left portion and high on the right. Focus in on the left portion of the trough – here, the B wave is low and the A wave is low. Track one of these points of low-low. Imagine that the motor came to a standstill on one of these points, and the animation stopped moving. If you were looking from within this low-low trough, you would see an B waveform high to the left, and an A waveform high to the right. Either direction you spin the motor, you would run into one, and only one, of these rising edges first. This is how one can track motor direction.\nPut another way, the encoder’s current state is listed like a coordinate pair, {AB}, where a low-low trough is represented as {00}. No matter the current state, whether it be {00}, {01}, {10}, or {11}, there are only two possible next states. Each possibility corresponds to a different direction.\nGreat! So, if we track the timing of the waveform edges, we get rotational velocity – if we track the state of each wave, we get motor direction. How do we translate this into C code which we can implement on a microcontroller (MCU)?"
  },
  {
    "objectID": "labs/lab5/lab5.html#introducing-interrupts",
    "href": "labs/lab5/lab5.html#introducing-interrupts",
    "title": "Lab 5",
    "section": "Introducing: Interrupts",
    "text": "Introducing: Interrupts\nFundamentally, the question is how best to track these edge changes. There are two broad categories which describe the two different fundamental implementations – a solution either uses interrupts or polling. Polling is the easier to implement. One could track the edges by “looking” at the signal at a set interval. For example, one could check the status of the encoder every 10 milliseconds, thus constructing a discrete graph of the signal over time. This is much like we programmed into our Lab 3 keyboard scanner, which checked every row of the keypad for a millisecond. Detection was not instantaneous – it relied on a polling time that was fast enough to pick up inputs “as if” in real time.\nInterrupts, on the other hand, are more difficult to implement on an MCU. However, they can be more useful when a precise response to real-time inputs is required. Instead of relying on the central processing unit (CPU) to track a timer and poll the input, a dedicated peripheral watches for changes. This peripheral then reports changes to the CPU, which temporarily pauses its main task to handle the generated “interrupt” before returning to its previous function. In this way, one can track the status of a wave as it changes in real time, while at the same time leaving the CPU to handle other tasks along the way.\nWhen choosing between the two, I should first state that I always planned to use interrupts for this lab – after all, that was a core learning goal. However, I believe that it represents the better choice in this case because it is the only way to construct a full, non-discrete image of the waveform. I use non-discrete loosely here, because we are still limited to checking for an interrupt on every CPU clock cycle, but the key point is that we can track changes with for more accuracy than we could in a polling system. By only checking for changes in the system, we can construct a much fuller picture while reducing CPU overhead. Note, however, that there is a limit. We can only log our edges as fast as our CPU can process interrupts. This case happens to work well, since I calculate that we might generate up to 5000 interrupts a second, leaving &gt;3,500 clock cycles between interrupts. If we were to generate a million interrupts a second, on the other hand, then my interrupt-handling code is likely too long to keep up. My printing code in the main loop would never run, and I would under-count generated edges. This could be partially fixed by interrupt-proofing my print loop, or by making the timer generate a higher priority interrupt to print, but neither of these measures were necessary for my relatively slow case. Additionally, interrupts work well here because I am only expecting one signal to change at any one time. I would need to fundamentally redesign my system if I was expecting a sudden influx of signals changing in parallel, since each interrupt change would be backlogged behind another. However, if I was truly getting into sub-microsecond changes and logging multiple parallel signals, I would likely choose to use an FPGA anyways."
  },
  {
    "objectID": "labs/lab5/lab5.html#microcontroller-block-diagram-and-schematic",
    "href": "labs/lab5/lab5.html#microcontroller-block-diagram-and-schematic",
    "title": "Lab 5",
    "section": "Microcontroller Block Diagram and Schematic",
    "text": "Microcontroller Block Diagram and Schematic\nTo implement an interrupt-based system on my MCU, I first had to choose how I planned to measure my system. Initially, I supposed that timing the difference between pulses might offer the best way to determine my motor’s speed. However, after this idea ended up producing significant error (up to 25%!), I instead pivoted to measuring the amount of pulses in a longer, fixed time. In order to measure direction, I stuck to the stage-based system which I previously discussed.\nTo turn this into code, I chose to create a main loop which contained a frame timer and my printing logic. This main loop was responsible for initiating and waiting for a half second timer, calculating revolutions per second (RPS), and printing to the user. In order to calculate RPS, I could create global variable logA and logB. Each time an edge came, I could increment the related logX variable. So, by manipulating the logX variable according to the equations in Figure 2, I could prepare them for the print statement. Speaking of, the print statement was relatively straightforward. By leaving the SEGGER debugger attached to the MCU via microUSB, we could print to it at our whim. I followed a tutorial created by Kavi Dey, found on a website of his here. You can find out more about my implementation by looking at my Github code, in the source &gt; lib folder titled DEBUG.\n\n\n\n\n\n\nFigure 2: Equations to yield final average Revolutions Per Second of motor\n\n\n\nThen, in order to track direction and actually log the pulses, I made use of interrupts. In the MCU, we can use logic contained within a GPIO pin block to monitor a signal, generating a unique interrupt for each A and B signal. By setting this interrupt to occur on each rising and falling edge and logging the respective logX variable, we can properly give the main function everything it needs to calculate the RPS. By tracking the state of the system at the beginning of each interrupt, then comparing it to see what direction the motor is traveling, we can thus determine direction and log that in a global variable visible to the main loop. A summary of this description may be found in the flowchart in Figure 3 below.\n\n\n\n\n\n\nFigure 3: Flowchart describing main loop and interrupt code behavior\n\n\n\nFinally, attaching this system to our MCU is straightforward. We are given a 25GA-370 DC motor, with the datasheet our class references available here. It requires a DC voltage supply between 0 and 12V, which I provided from a benchtop power supply (as seen in the system demo video above). I chose to attach the A encoder and B encoder signals to GPIO A and B ports respectively, making the code easy to parse. The simple schematic may be seen in Figure 4 below.\n\n\n\n\n\n\nFigure 4: Hardware schematic – note that VoltageSupply + and - refer to an external benchtop connection. DC Motor Used: 25GA-370"
  },
  {
    "objectID": "labs/lab5/lab5.html#testing-the-system",
    "href": "labs/lab5/lab5.html#testing-the-system",
    "title": "Lab 5",
    "section": "Testing the System",
    "text": "Testing the System\nAs I tested version two of this system – which counts pulses within a 500 millisecond framing window, instead of timing between pulses – I noted a constant error. My output values seemed to be near 20% lower than my actual RPS. How do I know? I measured it, using a tool called a tachometer. This handheld tool, seen working in the video linked here, uses a laser and reflective tape to accurately calculate the RPM of a mechanical system. Using this, I was able to generate the table in Figure 5, describing my MCU captured values against my Tachometer values.\n\n\n\n\n\n\nFigure 5: Error table\n\n\n\nThis table shows a consistent error, where my output value is between 21.1 and 22 percent lower than the actual value, assumed as equal to the tachometer. This consistent error is confusing to me. The first place I checked was my frame timer – if this was shorter than anticipated, then it would be under-reporting the true RPS. However, after counting a sequence of 60 cycles, I found that it was in fact under-reporting… by 1.06%. This is nearly within the error on the system clock itself, and certainly not significant enough to describe the consistent error. I then wondered if I could somehow be going too fast, and missing interrupts. However, the consistency of my error across voltages made me consider this a poor explanation. If this were the case, then I would have expected the error to grow with voltage as the system missed a larger and larger portion of the available pulses. Even now, I see no reason for this 22% error. It is not a simple factor of two error, nor could I imagine how it might come from my calculations. If only my B encoder counted at half the rate, then this could lead to a close ~25% drop. However, I checked both my A and B counters separately and they both had the same independent error. So, I do not know the source of this error.\nHowever, I do know how to fix it. Since it is a constant error, applying a simple multiplication factor does the trick. However, I felt that it would be simplest to add this value in as an integer. To do so, I decided to add in a topFactor and botFactor integer to my code, effectively scaling my answer by (topFactor/botFactor). The closest integers I could find under 1000 were topFactor = 947 and botFactor = 740. Using these integer values introduces an error of &lt;0.05%. After implementing this scalar, my printed RPS values were extraordinarily spot on. As seen in Figure 6, I was able to measure in a velocity with an error below 1%, sometimes approaching nearly 0.1%. I am quite pleased with these results, even if I am unable to locate the mysterious 22% error.\n\n\n\n\n\n\nFigure 6: Tachometer and example, running at 617.5 Revolutions per Minute (10.29 RPS)\n\n\n\nWatch the Tachometer video here!! Youtube wouldn’t let me embed it here since I filmed vertically.\nFinally, I want to mention that the system correctly reads out the direction, recognizing a clockwise, counterclockwise, and stopped motor."
  },
  {
    "objectID": "labs/lab3/lab3.html",
    "href": "labs/lab3/lab3.html",
    "title": "Lab 3",
    "section": "",
    "text": "Quick Stats\nTime Spent: 21 Hours, 45 Minutes, 57 Seconds\nSystemVerilog Modules: 10\nTotal FSM States Created: 16\nTestbenches: 5\nTime Wasted on a Busted Keyboard: 1 hour 13 minutes\nMind Melting Bugs: 2\nButtons Mashed for Testing Purposes: a lot\nOverall: Success\nSee my Blog Reflection for more!"
  },
  {
    "objectID": "labs/lab3/lab3.html#lab-task-out-with-the-switches-in-with-the-keypad",
    "href": "labs/lab3/lab3.html#lab-task-out-with-the-switches-in-with-the-keypad",
    "title": "Lab 3",
    "section": "Lab Task: Out with the Switches, In with the Keypad",
    "text": "Lab Task: Out with the Switches, In with the Keypad\nRecall that in Lab 1, students used their FPGA to control a seven segment display. Lab 2 added an additional layer of complexity, asking students to double the inputs and double the displays without doubling the hardware and GPIO burden.\nLab 3 gives students a straightforward task. Maintaining the dual display system, swap out the 8 switch inputs for an 8-pin, 16 button keypad. With the goal in mind, let’s dive right in!"
  },
  {
    "objectID": "labs/lab3/lab3.html#understanding-the-hardware",
    "href": "labs/lab3/lab3.html#understanding-the-hardware",
    "title": "Lab 3",
    "section": "Understanding the Hardware",
    "text": "Understanding the Hardware\n\n\n\n\n\n\nFigure 1: Keypad\n\n\n\nThe keypad took me some tinkering to understand fully. Pictured above, it has 8 pin outputs, labeled 1 to 8 from left to right. The pins create a 4x4 matrix, where each node represents a switch. Pressing a particular button connects that node’s column line to that node’s row line. In this way, each of the 16 buttons may be represented by a unique connection between one row line and one column line. By using a multimeter to reveal continuity, I created the following scratch note sheet for myself, describing the connections that each button makes between each pin. Note that the layout in Figure 2 below matches the orientation of the buttons in Figure 1 above.\n\n\n\n\n\n\nFigure 2: Keypad Note Sheet\n\n\n\nSo, the question then becomes – how does one detect these pin connections as they happen? Consider if you set all of the column pins to a logical high, and left the row pins logical low. Pressing one button, say the number 1, would connect the Row 0 and Column 0 lines together. Thus, the logical high value could pass from the column pin 3 to the row pin 8, where it could be read out as an input. However, how would you know which button in the row was pressed? You would have no way to determine whether the connection was made by the 1, 2, 3, or A button, any of which would connect a logical high column to Row 0. Instead, one could imagine setting all of the row and column pins to low. By setting only one column pin high at a time, you allow the input row pins to determine which button is being pressed. If Row 1 reads in a logical high while only Column 2 is similarly high? The user must be pressing a 6. If the user holds down this 6, the row pin should only register an input every time the high column pin cycles back around. By scanning through each column in sequence, we can thus read out all 16 buttons on the keypad. Figure 3 below shows some of this in more detail, diagram-style.\n\n\n\n\n\n\nFigure 3: Keypad matrix diagram and the basics of column scanning\n\n\n\nOne might note that Figure 3 seems to show the columns scanning through a single logical low bit, rather than a logical high. Knowing that the FPGA pins have internal pullup resistors, I opted to switch the polarity of the logic. I opted to keep all of the keypad columns logical high, and scan through with a single logical low value. I could then read any logical low row pins as an input button pressed. I made sure I had a reset set up, reused the same display multiplexing schematic from Lab 2, and wired up my keypad to the same pins the switches used to occupy. I kept the LEDs in use on the E155 protoboard, using them as a debugging tool. Figure 4 below shows the schematic, which may be viewed in more detail under the notes and extras folder in my Github.\n\n\n\n\n\n\nFigure 4: Hardware Schematic"
  },
  {
    "objectID": "labs/lab3/lab3.html#dealing-with-bounce",
    "href": "labs/lab3/lab3.html#dealing-with-bounce",
    "title": "Lab 3",
    "section": "Dealing with Bounce",
    "text": "Dealing with Bounce\nOne key flaw in most any physical button or switch hardware is its tendency to bounce. Bounce is when a connection is made and broken multiple times over a very short timespan, often occurring when a connection is first made or first released. Taking our buttons, for example, they have a springing mechanism which keeps them open. When they are depressed, they make a satisfying click. This is the physical deformation of the button, going from one relaxed “on” state to a similarly relaxed “off” state. The stage in the middle is unstable, and forces act to drive it either fully open or fully closed. These forces, coupled with the spring mechanism and rigid nature of the button, cause this bounce phenomenon as a button snaps and unevenly settles between states.\nSoftware designers need to have an understanding of debounce techniques in order to code robust software which is capable of ignoring bounce. For example, you wouldn’t want 10 “b” letters logged in the span of a microsecond. It is safe to assume that those repeated loggings were due to bounce, and should represent only one button press. On the other hand, maybe two or three button presses in a second are possible, and must register as distinct inputs. To find the difference between a bouncing input and a steady, true input, I decided to use a counter system. When enabled, this counter system initially gains some middle value. As the clock cycles, every time the input matches a true button press, the counter ticks up. If the button indicates a false input, or a still bouncing button, the counter ticks down. The counter module reads out a result if its value reaches either the upper bounded top rail, or the lower bounded bottom rail, indicating either a true input or a false input respectively. Figure 8 in the System Design section below shows the diagram of this system.\nThis would not be the only way to account for debouncing. One other way to avoid logging false inputs would be to slow the whole system down, making each clock cycle significantly longer than the time a button would take to bounce. However, I did not like this option. First off, the counter system gives me an easy knob to tune – the value at which the counter starts, and the value of the top rail. By adjusting these values, I can test my hardware to find the right balance between delay and speed without affecting the rest of my system. If I were to implement a slow clock system to account for bounce, my adjustment parameter then affects the entire system. This is undesireable. Additionally, I was worried about imperfect and rocking buttons momentarily disconnecting the input button as it was held down, causing an additional form of bounce and reconnection that would register as an additional press. I feared that this slow clock system would be more liable to register such an intermediate bounce as a new button click, since it had less data to use as a reference.\nAnother way to address bounce would be to wait a fixed time before reading in the input again. This gives the designer control over a similarly easy-to-tune parameter, and mimics the method often used in many DIP push button MCU systems. In my case, however, I again felt that collecting and comparing more data was better than comparing less data. By sampling the signal multiple times with my counter, I make sure that I am not beholden to any single cycle of bouncing."
  },
  {
    "objectID": "labs/lab3/lab3.html#system-design",
    "href": "labs/lab3/lab3.html#system-design",
    "title": "Lab 3",
    "section": "System Design",
    "text": "System Design\nIn this lab, the challenge is implementing this system into hardware. In order to describe how information is stored and passed, I created a Moore Finite State Machine (FSM). The FSM diagram in Figure 5 below illustrates my scanning system, polling through each column of the keypad. Note the general stage titles of the system on the left. This scanning through the columns is the core of the system, in scanColsX. The addition of synchronizers on the input necessitate the addition of two boot states to delay the system. If a valid input is read in, the system kicks over into the verification stage, where the goal is to make sure that the signal is one valid button pressed. This stage attempts to account for button debounce, which is discussed later in this lab. If the input is valid, the system then moves into the Set and Hold stage, where the input is sent out to the seven segment display and the system is placed into a holding state until all buttons are unpressed.\n\n\n\n\n\n\nFigure 5: Moore state diagram for scanFSM module\n\n\n\nTranslating this into clear and specific inputs and outputs, the state transition table in Figure 7 below describes the specifics of the system. Figure 6 describes the inputs with some simple matrices and describes each of the variables in the table.\n\n\n\n\n\n\nFigure 6: Input tables, & variables used in my FSM, state transition table, and actual SystemVerilog code\n\n\n\n\n\n\n\n\n\nFigure 7: State transition table for scanFSM module\n\n\n\nAdditionally, I wanted to flesh out the counter modules, since they would need simple FSMs of their own. Since they are relatively similar, Figure 8 describes both modules by the same general diagram.\n\n\n\n\n\n\nFigure 8: FSM diagrams for ensureCounter and holdCounter modules\n\n\n\nFinally, I needed to sketch out how each module connects using a block diagram. Note that this block diagram isn’t nearly as neat as I would normally prefer – however, in this lab, the real meat and potatoes is in the FSM diagrams. The block diagram in Figure 9 below merely serves to show how the wires connect in SystemVerilog. Note that int_osc and clk signals are different, accounting for the fact that the display multiplexer runs at a different frequency than the keypad scanner. Funnily enough, in the end, I ended up using the same value of 1000Hz for both. Therefore, I could have cut down the extra frequency generator inside the display module.\n\n\n\n\n\n\nFigure 9: Block diagram\n\n\n\nHaving designed the system, it was time to put it into SystemVerilog! The full contents may be found in the FPGA folder of my lab 3 Github repository, found here. Note that there are two main branches, corresponding to my code before synchronizers and after synchronizers."
  },
  {
    "objectID": "labs/lab3/lab3.html#simulation",
    "href": "labs/lab3/lab3.html#simulation",
    "title": "Lab 3",
    "section": "Simulation",
    "text": "Simulation\nSimulating this lab was a doozy, but essential to the lab’s success. Without simulation, it would have been near impossible to tell what was happening in my hardware. An oscilloscope helped me see the scanning of the columns, which coupled nicely with my onboard indicator LEDs and a reduced 1Hz clk signal to give me a debugging suite. My simulations all went off nearly without a hitch – I mainly spent my time fixing small syntax errors. The design work beforehand paid off!\nStarting with the simplest module, I tested the keypad decoder module in Figure 10 to verify that for a given column and row input, it outputs the correct hex input digit.\n\n\n\n\n\n\nFigure 10: Testbench for the keypad decoder module – Successful\n\n\n\nMoving onto the ensureCounter module, I verified that it cycled through states properly, activated its top and bottom rails as necessary, and counted as desired. It performed smoothly!\n\n\n\n\n\n\nFigure 11: Testbench for the ensureCounter module – Successful\n\n\n\nMoving now to the bigger beast, scanFSM, I loaded it up and was surprised to see that it too simulated after only a few small syntax or inversion errors. Note that this does not yet include the synchronizers. Specifically, referring to Figure 12, I checked to make sure the states cycled as expected, the correct row and column were held at the proper time, the intended digit was read out into the display input, and that it integrated with the counters to verify any button presses.\n\n\n\n\n\n\nFigure 12: Testbench for the scanFSM module – Successful\n\n\n\nPutting this into hardware, it worked! I had some issues at first with a prolonged button press with several intermediate presses registering as multiple presses of the first button. Changing my default case in the pinReader module fixed this issue. Additionally, I had some issues with my state register when I synthesized it with Lattice Radiant and uploaded it to my FPGA. Strangely, the software did not warn me and I was stuck for quite some time. After more clearly defining all of my defaults, the system worked. I predict that the synthesizer was recognizing my creation of an FSM and attempting to optimize the state encoding and logic – unfortunately, this caused some of my default cases not to apply as they should have. After speaking with Professor Brake, he hinted that this may just be an unfortunate quirk of the software."
  },
  {
    "objectID": "labs/lab3/lab3.html#synchronizing-the-inputs",
    "href": "labs/lab3/lab3.html#synchronizing-the-inputs",
    "title": "Lab 3",
    "section": "Synchronizing the Inputs",
    "text": "Synchronizing the Inputs\nFinally, the trickiest excellence specification for the week asked students to add in synchronizers to their inputs. A synchronizer is a mechanism to avoid metastability in a synchronous system with asynchronous inputs. In our case, all of our keypad presses were asynchronous inputs, and reading them on a clock edge as they changed could put our synchronous logic into a dangerous middling state, where the logic recognizes it as neither high nor low. This can propagate and ruin systems, or at the very least, cause some incorrect bits when it does occur. However, most metastable inputs settle over time. The goal of a synchronizer is to increase this settling time on the input before introducing it into your system. By stringing the input signal along between, say, two flip flops, you can give the input signal two additional clock cycles of time to settle to a logical low or logical high. So, that’s exactly what I did!\nHowever, introducing synchronizers adds an additional layer of complexity to the system. As Figure 13 illustrates, these synchronizers delay the inputs into my system. As I scan along the columns, there is now an introduced two cycle delay between when my input reads out and when my FSM registers it. Referring to Figure 5, one can see that an input read into scanCol1 would not register until the system had moved onto scanCol3. That is to say, the delay mismatches the “scan” value at any given time with the “scan” value which correlates to the currently read input. In order to solve this, I added in two registers which store the two most recent prior values of scan. Thus, by referencing back to the value twoPriorScan, I can properly match the delayed input sense with the delayed output scan.\n\n\n\n\n\n\nFigure 13: The problem with synchronizers in my system, illustrated with waveform inputs\n\n\n\nHowever, this in and of itself is not enough. The FSM in Figure 5 thus needs two cycles to load in the most recent input and output values. So, I gave the system two extra cycles to boot and store new information before it drops into its regular scanning cycle. Likely, I did not need these additional stages. I may have gotten away just fine by letting it loop back, and building in more conditions into how the system moved into the initialize stage. However, I found it simpler and easier to understand if I instead added two boot delay states.\nAs I coded these synchronizers into SystemVerilog, I again wrote some simple testbenches. The first one, in Figure 14 below, shows the intended two cycle delay and polarity flipping on the new pinReader module.\n\n\n\n\n\n\nFigure 14: Testbench for the pinReaderSynchronized module – Successful\n\n\n\nFinally, Figure 15 shows a successful run of the top module with all synchronizer code built in.\n\n\n\n\n\n\nFigure 15: Testbench for the synchronized top module – Successful"
  },
  {
    "objectID": "labs/lab3/lab3.html#final-system-and-conclusion",
    "href": "labs/lab3/lab3.html#final-system-and-conclusion",
    "title": "Lab 3",
    "section": "Final System and Conclusion",
    "text": "Final System and Conclusion\n\n\n\n\n\n\nFigure 16: System Preview\n\n\n\nAnd with that, I had my final system! My blog post for Lab 3 contains more details about the second mysterious bug that I encountered, and my feelings on the matter. This lab wasn’t as frustrating as I think it was for some – although I encountered my share of confusion, I always felt like I had a clear path forward. My final system is incredibly robust, successfully able to avoid many forms of multiple-button presses while responding to valid inputs in a snap. I wish that I could have been better able to deal with two simultaneous button presses in adjacent columns. In fact, I am surprised that the system seems to handle it as well as it does. I’m not exactly sure what causes it to ignore simultaneous adjacent column presses. However, I did successfully add synchronizers, avoid logging interstitial short presses over longer simultaneous presses, and ignore simultaneous presses along different rows. I’m proud of my work in this lab, although I recognize that there is room for improvement, both in terms of functionality and FPGA efficiency."
  },
  {
    "objectID": "posts/lab1-post.html",
    "href": "posts/lab1-post.html",
    "title": "Lab 1 Reflection",
    "section": "",
    "text": "As I write this reflection, I am still riding the high of making 2 major adjustments to my Lab 1 source code – with nary an error along the way. It’s an incredible feeling. However, don’t get me wrong – I still failed. A lot. Like, way more than I usually do. But, that failure was intentional. It was a stated part of my learning goals, and I can tell it’s already paying dividends.\nReferring back to my first post on learning goals, I only listed a brief two. I felt that these most effectively summarized the litany of knowledge and skills which I hoped to gain from this course.\n\nGain an understanding of FPGAs and their applications; and\nIncrease my Autonomy (by failing more often).\n\nLab 1 did indeed give me my first introduction to FPGAs. I understand them now as powerful tools which may be simply harnessed using SystemVerilog and Lattice Radiant. That is to say, I understand how one can put most any desired hardware into SystemVerilog language, program it onto an FPGA, then connect that virtual hardware to the outside world through simple pin assignments. The limit is only drawn by your FPGA’s… capacity? Size? Configuration? I’m still sorting out the specific details, but my point stands – I recognize FPGAs for the effective tools they are, and can’t wait to jump into Lab 2 with this knowledge next week.\nHowever, I want to focus this reflection on my second learning goal, as I think it has seen the most impact thus far. Do you recall me saying that I failed a lot? Well, I meant it. I went into the MicroPs lab 6/7 days of the week to get this lab done to my expectation, and spent 18 hours working on it outside of class. Where did this time go? So little of it went towards what I traditionally consider “succeeding.”\nConsider a hallmark of Jackson Philion’s workflow – the first draft gets submitted. I agonize over each sentence, demanding near-perfection from every line, but make no mistake – once the final sentence has been written, I do not read it again. These 6 days in the lab did not follow this usual workflow. I revisited the same chunks of code over multiple days, making revisions on already-functioning pieces to polish up the result. Nor did these days meet my traditional standard for success, as I went home on more than half of them knowing that I would see the same error messages tomorrow. Two years ago, I would have been infuriated with these “failings” and “inefficiencies”. A year ago, heck even a couple months ago, I would have gone on hours-long lab binges until I could leave with a sense of success. Now, don’t get me wrong, I still had one lab binge… after all, we’re all just works in progress, right? However, as I sit here still riding the high of my relatively error-free night, I feel success in those days that I failed. I think back, and I realize that I never felt that sense of impending doom called failure. I looked forward to taking my next crack at it tomorrow, during my planned lab time. While I worked alongside friends, I didn’t lean on them to help me resolve my errors to the usual extent. I made an intentional effort to let myself try and fail at least 3 times. Most often, this resulted in a new piece of learning that may not have been conveyed otherwise. Instead of feeling like agony, these moments were more jovial than I expected.\nI think I am reveling in the challenge that this class represents. As I have mentioned before, I have been hearing about this class and building up to it since I was a freshman. I think I have bought into some vision that this is the class which is meant to forge oneself into a high-performing professional. In this mindset, it is easy for me to embrace new workflows, new schedules, and new failures. It’s easy to start week one of the course and give it my all, and it’s easy to see the success and learning that failing autonomously has brought me. After 18 hours spent combing through documentation and forums, I am proud to say that my most recent edits had no errors because I had already gotten them all. Not because I was perfect, but because I failed and revised enough to find the right path. And right now, it feels great.\nLooking forward, I am considering what next week will bring. To make a crude analogy, I feel like I am feasting on ham after winning the war’s first summertime battle. I fought, I struggled, and I won. I was surrounded by my A-team… tutorials, quick-start guides, and similar week-one aids. I didn’t have other classes yet vying for my attention. In short: I was surrounded by things that made it easy to fail and get right back up again. However, this is a semester-long class, not a summer workshop. I need to win the war, not just the battle. I need to win the battle in the dead winter when supplies have been low for weeks. Sure, I’m on the right track now, but will I still be when my first Politics essay is due? When technical work with HRL Labs Clinic begins in earnest? When I come back from Thanksgiving break and have to motivate through Finals? I think I need to spend some time preparing for that eventuality, rather than letting it get the best of me.\nThat is to say, this week I am feeling great. I am thoroughly excited to pursue the rest of this coursework, and to try out new things: failing, reflecting in these posts, writing up my work thoroughly, partitioning the workload like a job. But I’m nervous to see how I respond when failing starts to feel… not good. That will be the true test of my learning goals. I can’t tell whether I actually want that point to come or not. For now, I guess we’ll remain in suspense until next week. September 8, 2024."
  },
  {
    "objectID": "posts/post-24-10-18.html",
    "href": "posts/post-24-10-18.html",
    "title": "My New Hack for Debugging",
    "section": "",
    "text": "With Lab 4 bringing about a switch in focus to our other hardware unit – the Microcontroller Unit (MCU) – I’ve been running into unfamiliar bugs. More than unfamiliar, some of the SEGGER error messages are downright unhelpful. On the other hand, I’ve grown quite fond of SystemVerilog and Lattice Radiant’s error messages. Sure, their line number is usually a couple off from the problem, but the error messages are descriptive and get the job done. I feel in control of SystemVerilog errors, and know almost instantly when one is going to require special attention. Now, in the land of the MCU, SEGGER, and C, I feel a bit lost with each new error message.\nI think of each debugging journey like a scavenger hunt. A SystemVerilog scavenger hunt might have a first clue that sends you to the third drawer of the old hutch in the attic. Inside, you find a spot the difference puzzle that reveals your final answer. Sure, the clues may be a mild challenge to locate, but the solution is typically straightforward and satisfying.\nOn the other hand, in a C scavenger hunt the first clue you get is to find ‘something round’ in a forest of identical trees. After wandering around for a while, you find a note taped on a branch which reads “the second clue is written in invisible ink on the back of a squirrel.” Good luck.\nNow, in all fairness, give me a couple of weeks and I’m sure I’ll be able to tell you which squirrel to look for. After all, I haven’t brushed up on my C skills in nearly a year. However, the learning curve has proved to be steep.\nHowever, that isn’t the point of this post. I’m here to share what has gone well in the face of these seemingly intractable errors. I’ve found one particular technique that has helped me debug more efficiently and effectively, and it has the side benefit of building up my writing skills.\nFor those who don’t know, our class has a Discord channel started by our professor. It has discussion sections for each of the labs, where students can post questions and (hopefully) get help from the professor and peers. People don’t post as much as I would have imagined – some labs have no discussion threads, while others have just one or two. I know that I haven’t posted in the past largely because it just hadn’t been used before. I always had a classmate around to ask if I really needed, or knew when the next office hours was to get help in person. However, as I drove off with my friends for October break, my most recent bug lingered in my mind. I had tried googling and parsing through my code, but had no good answer. I had decided that the next best step was to make dramatic changes in the structure of my code. In a last ditch attempt to avoid this, I figured that I might as well post my question in the discussion thread first. To my surprise, a classmate responded within 5 minutes and the professor responded before lunch. They both gave me some helpful keywords to use as I searched to understand and find a fix (turned out, “include guards” was half the problem).\nThis emboldened me. After returning from break, I ran into a bug on Thursday night that stopped me in my tracks. After an hour spent trying to fix it, I got nowhere, and the same problematic lines of code were as broken as ever. Knowing that I wouldn’t be able to attend office hours until after the weekend, and knowing that I couldn’t afford to pause the work for 4 days, I went to craft a discussion thread to ask my peers and professor for help.\nThe first time I tried to write the message, I quickly jotted down my thoughts in the span of a couple minutes. I hovered my mouse over the little arrow that meant “send”, then paused. Had I really tried everything I could think of to answer my own question? My brain flashed through the possible responses my peers could send… Have you checked the _____ section of the reference manual? Have you tried messing around with the lines of code directly before everything broke? The honest answer to many of these was – no. I had done some of the work myself, but I hadn’t yet exhausted every possible resource.\nAs I realized this, my mission pivoted. I wanted to write the most bulletproof, well-reasoned explanation of my bug that I possibly could. I figured that throughout this process, I would either solve the problem on my own or come up with the an extremely well-documented bug report. The problem would either solve itself, or be worthy of a new post.\nWhy has this idea only now come to my mind? As the semester has drawn on, I find it more challenging to work near my peers. Different classes consume us at different times, and several of my closest friends have makeshift laboratory setups in their own rooms. That is to say, I am more and more often working alone in the Digital Lab. This is why writing out discussion posts has been so valuable to me – it has reminded me the value of considering a fresh perspective, challenging my assumptions, and bouncing ideas off of a peer. It lets me go through that process without needing to wait until my next work block with Ket or office hours after the weekend.\nThis is my new challenge to myself – I want to be more active in the class Discord discussion threads. Although there aren’t a plethora of other student posts, I want to make a more active effort to respond to them. More importantly, however, I want to commit to writing out my own questions more often. I want to commit to only sending them once I’m well and truly convinced that I have exhausted my own reserve of possibilities. I figure that if I adhere to this, I will become a better problem solver while I practice writing effective problem reports."
  },
  {
    "objectID": "posts/post-24-10-10.html",
    "href": "posts/post-24-10-10.html",
    "title": "The Limitations of C and Me",
    "section": "",
    "text": "Unlike my other posts, I have no finished lab to reflect on this week! I am in the midst of working through the bugs in my code on Lab 4, and eagerly await the moment when I hit “download” and hear the electronic tones of Für Elise. Until I hit that point, however, I want to take a moment to describe my experience this week, when I took a skills assessment as part of a job application."
  },
  {
    "objectID": "posts/post-24-10-10.html#getting-set-up",
    "href": "posts/post-24-10-10.html#getting-set-up",
    "title": "The Limitations of C and Me",
    "section": "Getting Set Up",
    "text": "Getting Set Up\nThrough my internships and job applications thus far, I have never been asked to complete a written/tested skills assessment. I think this is because I most often end up applying for and working at smaller start-up companies, where a less rigid hiring structure is expected. I have been asked to demonstrate knowledge, or expand on what technical knowledge my experiences have taught me, but never in a format more closely related to a midterm than a conversation.\nThis time was different. After downloading a test proctoring software, I was prompted to begin the multi-part test. A timer in the corner counted each second as I was asked question after question on basic math, coding syntax, logic puzzles, and more. Finally, I reached the free response section, where I was prompted with several functions to build in any language of my choosing.\nNow, it is important to note: the introduction to the assessment had stressed repeatedly that no prep was necessary, emphasizing that the role did not require any particular flavor of programming experience. It stressed that general familiarity with coding patterns and thought processes was most important, no matter the language. Given that I had spent the past several months immersed in C and SystemVerilog, and had been doing prep for other similar jobs anyways, I figured that I was fresh enough on my “general coding knowledge” to take a stab at the assessment."
  },
  {
    "objectID": "posts/post-24-10-10.html#the-test-and-my-own-personal-island",
    "href": "posts/post-24-10-10.html#the-test-and-my-own-personal-island",
    "title": "The Limitations of C and Me",
    "section": "The Test, and My Own Personal Island",
    "text": "The Test, and My Own Personal Island\nThe first question asked applicants to create a function to manipulate a string of text. Simple! I had done this many times in the past in Python, and implementation should be a piece of cake. I clicked in the field to start creating my answer and… paused. Crap. I didn’t remember how to format a python function. I hadn’t thought to review it before this assessment because I had yet to be asked a question on Python in any interview. Looking back, of course I should have reviewed it. It was too late, however. After several stabs at writing a python function, none of them quite looked right.\nI felt like I had blinked and found myself on a deserted island with only a torn rucksack, a half-drunken canteen bottle, three toothpicks and a crumpled pack of crackers. I needed to build a raft to escape, but I had just realized that I had left my saw at home. It was time to take stock of my resources, and the blinking red light recording my computer screen reminded me that I had to move quickly. This led me to my first realization:\nNot all coding languages are created equal, and some are downright useless for a particular task.\nStanding on that desert island, I reached into my pack and pulled out an old calculator. Matlab. I had spent a good deal of time using this my sophomore and junior year, and knew that it had character manipulation functionality. However, when I took the cover off the back and wiggled around the batteries, I remembered that I had only ever used it for manipulating matricies, calculating differential equations, and digitally processing signals. Sure, it was useful stuff, but it wasn’t going to help me build a raft to get off the island. As the lighted display on the calculator flickered and died, I tossed it to the side.\nReaching back into the pack, I next pulled out a pencil. SystemVerilog. Intimately familiar with this tool from my past year of study, the familiar weight settled into my hand nicely. However, Verilog is a Hardware Description Language (HDL), not a coding language. My professors had drilled this into me, and yet I had never appreciated it as much as in this moment. Sure, I could use the pencil to draw whatever kind of raft I wanted, but it would never have the same kind of substance and power that a coding language like python, java, or matlab does. It can create an effective design, but it is reliant upon the hardware that you give it to synthesize into. I tucked the pencil into my pocket, steadied myself with a sigh, and dug back in.\nHTML? Nope, useless here. CSS? Ditto.\nThat left me with one option left. My trusty old pocket knife, C. It isn’t glamorous. It isn’t winning any awards for ease of use or complexity. It’s just good ’ole, reliable C. This, I recall immediately. Realization two:\nProgrammers refer to C as a low level language for a reason.\nC is great for embedded systems. It lets you control, with extreme authority, every action and function of a microcontroller with a memory-mapped control system. It lets you manipulate individual bits of data, and store things and efficiently or inefficiently as you wish. Things it’s not so great at? Implementing higher complex logic easily. You have to build these sorts of functions from the ground up. That is why so many standard C libraries exist. Such standards let designers use more powerful functions as basic building blocks without having to reinvent the wheel. This functionality balances precice control and function with ease of use and design.\nMultiple programmers have already come together to create a standard suite of funcitons called I &lt;ctype.h&gt;. I did not know about this suite, as I do almost no tasks requiring string or character manipulation. This left me to do my best to build out these basic functions first, before I even got to working on a bigger picture function to accomplish the task. Back to my island analogy, I was trying to build a raft with a pocket knife. It was possible, sure, but it wasn’t the right tool for the job.\nIt was arduous, especially without any debugging tools, reference material, or experience working with character/string syntax. I can guarantee that what I wrote does not run. In many ways, it was demoralizing – here I am, an electrical engineer with experience in these languages, scrapping together my best guess at a dictionary in C. I had a lot of time to think as I sat there trying to carve my raft. I can only imagine what the test assessor will say when they see the function – I imagine there will be some amount of laughter."
  },
  {
    "objectID": "posts/post-24-10-10.html#the-vulnerability-of-a-job-search",
    "href": "posts/post-24-10-10.html#the-vulnerability-of-a-job-search",
    "title": "The Limitations of C and Me",
    "section": "The Vulnerability of a Job Search",
    "text": "The Vulnerability of a Job Search\nI’m glad for the experience, however, job or not. I had never been left to consider my knowledge in such a way. It is not often that I am given a test which I feel unprepared for – I try explicitly to make sure that doesn’t happen, in fact. It made me default back to the problem solver that I am at heart. I could not check, or verify, or debug any of my work. I saw my most basic qualities reflected back at me. Each line was written carefully and deliberately. The whole text was thoroughly commented, as I work best when explaining my thinking out loud or with a peer. At points, I heard the little voice in my head tell me that I should just quit the assessment. When my gaze wandered, looking for a small respite from the insecurity that I felt looking at my code, I saw the blinking red light in the corner. It felt like I was in a fishbowl, with the software recording my every move. It was a deeply humbling experience, unexpected on a Tuesday at 12:10pm before lunch. It revealed to me the expectations that I implicitly hold myself to, and how my brain operates when I am not meeting those expectations.\nI finished most of the assessment in nearly 3 hours, at which point I could continue no longer. It turns out that nervously drinking water throughout the assessment was a poor choice. However, I can confidently say that I gave it my best shot – my brain was starting to melt at that point. I feel sure that my problem-solving process is clearly described within the online pages of the test, which is the most I can ask for. If they decide that I don’t fit the bill, then so be it. I have found myself thinking way more about the process itself than the end result anyways.\nI’ll be curious to see how many similar skills assessments I do in the future, and how I respond to them. After this, I certainly will struggle to expect anything except the unexpected from these kinds of interviews and assessments. Each time I think I’ve prepared well, I seem to get hit with the question that I hadn’t considered.\nThe job hunt is a deeply personal, vulnerable process. It demands that you be your best self, and your most authentic self, at the same time. It tells you not to worry about your weaknesses, and to focus on your strengths. And yet, throughout the entire process, you are poked and prodded to reveal flaws and missing knowledge. It brings out the best in people while also plainly laying out all of the possible reasons for rejection. It is a maddening dichotomy and an uncomfortable process.\nYet, the job search is a fact of life. More than that, it is uncomfortable because it is a process of growth, change, and soul-searching. I hope that it has the intended outcome – a job that I see a future for myself in. But, for now, it’s already helping me be more introspective, less hell-bent on perfection, and revealing my Electrical Engineering work in a whole new light. In that sense, I guess that it’s already started to pay off."
  },
  {
    "objectID": "posts/lab3-post.html",
    "href": "posts/lab3-post.html",
    "title": "Lab 3 Reflection",
    "section": "",
    "text": "A large poster from David Agans hangs in the digital lab where I do my work, pinned right up above my favorite lab bench. I like it a lot – I find myself looking at it only after finding victory against a particularly tricky bug. I like picking out which steps of the process I just went through as I solved my bug. It reminds me that debugging is the other half of the digital design process, and that the seemingly ridiculous steps that one sometimes goes through when debugging are normal."
  },
  {
    "objectID": "posts/lab3-post.html#intro",
    "href": "posts/lab3-post.html#intro",
    "title": "Lab 3 Reflection",
    "section": "Intro",
    "text": "Intro\nLab 3 was an enjoyable process for me. I enjoy the process and the puzzle that debugging presents, untangling details until you find a missing link. I like fixing small syntax errors which separate a working design from a broken mess, or finding some slight conceptual difference between the idea you had and the implementation you designed. I love finding the nuances in the system.\nThis love helps me understand why two bugs in particular drove me so crazy during lab 3. I solved both of them, but understand neither. That is maddening – to stumble accidentally across the solution to a puzzle, and to know in your heart that you could not replicate the solution if you tried."
  },
  {
    "objectID": "posts/lab3-post.html#bug-one",
    "href": "posts/lab3-post.html#bug-one",
    "title": "Lab 3 Reflection",
    "section": "Bug One",
    "text": "Bug One\nThe first bug occurred when I implemented my system into hardware. It simulated perfectly and synthesized without error, but the FSM never even began. I tried most everything I could think of – I checked all my default cases, I checked the clock, I checked the state with debug LEDs, I checked to make sure the LEDs were working, I checked to see if the outputs matched any known state, but the only common thread was that something was broken and I couldn’t tell what. The fact that it simulated fine meant that the error was in the translation to hardware. Something about my system was either mistimed or improperly synthesized, such that the machine never even started, and the computer couldn’t catch it. After hours, I decided I would ask my professor, thinking that there was some higher knowledge I lacked which he could enlighten me with. After some time spent understanding my system, he agreed that something seemed wrong with my state registers, but wasn’t sure what. Most frustrating was when he said that my design might be programmed correctly, but that the synthesis software Radiant might be doing some behind-the-scenes magic that was actually breaking my system.\nThat moment was the most disheartened I had been during MicroPs yet. It felt like I had done everything the way I was supposed to, and had built a functional system, but had drawn the short straw and was told “no”. I had given my best effort at debugging, and been firmly smacked back down. As I slowly started to accept that my next best option was to simply scrap the whole project and rewrite it from scratch, I just kept fiddling with the code. Eventually, it worked. I’m not even sure what I changed. I wasn’t making logical changes – I was just praying that some inconspicuous change in the document would fix the secret synthesis error that Radiant was so devilishly hiding. So it did – one time, when I ran it, the entire system worked perfectly.\nI estimate that the error was either with Radiant optimizing away my default cases or mishandling my state register. Or, it is very possible that this first error was caused by the same issue which caused the second terrible horrible no good very bad bug of lab 3."
  },
  {
    "objectID": "posts/lab3-post.html#bug-two",
    "href": "posts/lab3-post.html#bug-two",
    "title": "Lab 3 Reflection",
    "section": "Bug Two",
    "text": "Bug Two\nThe second bug that occurred is even more maddening because I was able to pin the bug down to three lines of code. Mind you, four lines of code which should work perfectly normally. Three lines of code which were tied to the same debugging logic that I have been using since lab 1. Three lines which separated a completely broken system from a flawlessly working and synchronized keyboard scanner.\n// Working Code\nassign led[1] = (rowSenseHold[0]);\nassign led[2] = (rowSenseHold[1]);\nassign led[3] = (rowSenseHold[2]);\n    \n/* Inexplicably Broken Code\nassign led[1] = (state==verify);\nassign led[2] = (state==hold);\nassign led[3] = ((rowSenseHold==4'b0100)&(colScanHold==4'b0100)); */\nThe first thing that irks me about this bug is that I never would have caught it if I didn’t just keep tinkering around and exploring different sorts of errors. This is my debugging output logic, and I had no reason to find it faulty. I had no reason to change it except to learn more about the system. If this sort of error had occurred in a different part of the system that I wouldn’t have changed anyways, then I never would have caught it. It has absolutely nothing apparently connected to the synchronizer inputs which would cause the system to completely fail and lock up the way it did.\nThe second problem I have with this bug is that I still don’t understand it. Don’t get me wrong – I have some theories. But they’re just that – theories. I spent a long time going back and forth between these three little lines and probing contacts with an oscilloscope to diagnose the issue, but found nothing of note. My current working theory is that I have some small and hidden short circuit on my board which is affecting the pins which control my scanning and state circuit. No other explanation seems plausible to me, other than some wild Radiant synthesis error. These line should have no effect on the state system, and yet they shut down every single part of it. Something about tying the state of these pins into the state of the machine is breaking the system. So, these pins must somehow be shorting to the other pins, or Radiant must be creating some internal short circuit. It could be some other explanation, but I have no worldly idea what that would be."
  },
  {
    "objectID": "posts/lab3-post.html#general-wrap-up",
    "href": "posts/lab3-post.html#general-wrap-up",
    "title": "Lab 3 Reflection",
    "section": "General Wrap Up",
    "text": "General Wrap Up\nThis brings me back to debugging in general. It brings me back to the poster, and the principles it touts. I think that a big one missing is to examine the parts of your system which seem obvious, simple, or unconnected. These assumptions are dangerous since they create a blind spot in your debugging vision. I never would have fixed bug two if not for questioning everything, and going back to basics with my debug logic to check every single piece. It was in the process of checking rowSenseHold, a variable that was so straightforward that I hadn’t even thought to check it before, that I revealed the bug in a wholly separate debug system.\nI also think, though, that the poster can be a bit overly optimistic. It carries the hopeful implication that all bugs can be solved with perserverence and new thinking. I think that this is only partly true. It is tricky to square this belief with the sort of Radiant synthesis errors that I may have been encountering. If they were truly Radiant synthesis bugs, then I am lacking the level of higher knowledge necessary to fix and understand them. That’s frustrating. It puts me in a place where I can no longer approach bugs logically. I have to try rewriting bits of code to solve bugs that I don’t understand, in the hopes that I hit the jackpot. If I don’t? Tough. That’s a disheartening thought.\nSo, my relationship with debugging is growing stronger. I like it more and more, and feel more confident in many ways about debugging a complex system, and doing it efficiently. On the other hand, I encountered two errors that I don’t understand, and that could cripple me in the future. It feels like a dangerous game that I’m playing – how complex can I make my system before a bug that I could never expect and don’t understand brings it to its knees? Now, things change depending on what happened here in lab 3. If I find out a week from now that I really did have a short circuit error, then this entire case cracks open. I am put squarely back on firm footing, and given renewed confidence in my ability to diagnose and test for increasingly complex bugs. If, on the other hand, a similar bug in lab 5 presents itself and my only solution is to restart from scratch, or start taking a hatchet to chunks of code, then I will know that debugging has gotten the best of me this time.\nAs it stands though, I don’t want to get too into the doom and gloom. The headline here is that I encountered two incredibly complex bugs and still came out with some theories and a working system. Again, I enjoyed the process, and feel more and more like a practicing digital designer with each lab. I’m excited to see what the next chapter brings, and looking forward to dipping my toes back into the world of MCUs and C. Until next time!"
  },
  {
    "objectID": "finalProject.html",
    "href": "finalProject.html",
    "title": "Final Project",
    "section": "",
    "text": "Check out my Final Project here!\nMy partner and I implemented a Fast Fourier Transform on our MCU which processed an audio signal. We captured the signal using the ADC and DMA after sending it through a custom analog amplifier. Then, we displayed the signal out to the user via an LCD driver built within our FPGA.\nCheck out the final product and block diagram below, for reference. It was a pretty sweet system!\n\n\n\nFinal System\n\n\n\n\n\nBlock Diagram"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "E155 Course Website: Link to Website\nMy Github: Link to Website"
  }
]